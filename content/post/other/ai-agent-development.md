---
title: AI agent development
author: "-"
date: 2025-11-19T08:30:00+08:00
url: /?p=4058
categories:
  - Java
  - Web
tags:
  - reprint
  - remix
  - AI-assisted
---

# AI agent development

## å¸¸ç”¨æŠ€æœ¯æ ˆ

1. ç¼–ç¨‹è¯­è¨€

- Pythonï¼ˆä¸»æµï¼Œç”Ÿæ€ä¸°å¯Œï¼‰
- JavaScript/TypeScriptï¼ˆWeb/Node.js Agentï¼‰
- Goã€Javaï¼ˆé«˜æ€§èƒ½/ä¼ä¸šçº§ï¼‰

1. å¤§è¯­è¨€æ¨¡å‹ä¸ API

- OpenAI GPT-4/3.5ã€Claudeã€Llama
- Hugging Face Transformers
- LangChainã€LlamaIndexï¼ˆAgent æ¡†æ¶ï¼‰

1. Web æ¡†æ¶ä¸æœåŠ¡

- FastAPIã€Flaskï¼ˆPythonï¼‰
- Express.jsï¼ˆNode.jsï¼‰
- Django

1. æ•°æ®å­˜å‚¨

- Redisã€MongoDBã€PostgreSQLã€SQLite
- å‘é‡æ•°æ®åº“ï¼šMilvusã€Pineconeã€Weaviate

1. æ¶ˆæ¯é˜Ÿåˆ—ä¸å¼‚æ­¥ä»»åŠ¡

- Celeryã€RabbitMQã€Kafka

1. å®¹å™¨ä¸éƒ¨ç½²

- Dockerã€Kubernetes
- äº‘æœåŠ¡ï¼šAWSã€Azureã€GCP

1. å‰ç«¯äº¤äº’

- Reactã€Vue.js
- WebSocketã€RESTful API

1. å…¶ä»–

- Prompt å·¥ç¨‹ã€å·¥å…·æ’ä»¶ç³»ç»Ÿ
- OAuth2ã€JWTï¼ˆå®‰å…¨è®¤è¯ï¼‰
- æ—¥å¿—ä¸ç›‘æ§ï¼šPrometheusã€Grafana

## Python è°ƒç”¨æ¨¡å‹æ–¹å¼

AI Agent ç”¨ Python å¼€å‘æ—¶ï¼Œå¯ä»¥è°ƒç”¨æœ¬åœ°æ¨¡å‹æˆ–äº‘ç«¯æ¨¡å‹ï¼š

- æœ¬åœ°æ¨¡å‹ï¼šå¦‚ Llamaã€GPTã€transformersï¼Œå¯ç”¨ Hugging Face Transformersã€llama.cpp ç­‰åº“åŠ è½½ã€‚
- äº‘ç«¯æ¨¡å‹ï¼šå¦‚ OpenAIã€Azureã€ç™¾åº¦æ–‡å¿ƒã€é˜¿é‡Œé€šä¹‰ï¼Œé€šè¿‡ HTTP API æˆ–å®˜æ–¹ SDK è¿œç¨‹è°ƒç”¨ã€‚

é€‰æ‹©æœ¬åœ°æˆ–äº‘ç«¯ï¼Œå–å†³äºç®—åŠ›ã€æ•°æ®å®‰å…¨ã€æˆæœ¬å’ŒåŠŸèƒ½éœ€æ±‚ã€‚ä¸¤è€…éƒ½æ”¯æŒ Python è°ƒç”¨ï¼Œä»£ç å®ç°ä¹Ÿå¾ˆæ–¹ä¾¿ã€‚

> æœ¬æ–‡å†…å®¹ç”± AI è¾…åŠ©ç¼–è¾‘

## AI Agent å¤–å±‚ä»£ç ä¸æ¨¡å‹è°ƒç”¨è¯´æ˜

AI Agent é€šå¸¸ç”¨ä¸€ç§ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚ Pythonã€JavaScriptã€Go ç­‰ï¼‰ç¼–å†™å¤–å±‚é€»è¾‘ä»£ç ï¼Œè´Ÿè´£ä»»åŠ¡ç¼–æ’ã€æ•°æ®å¤„ç†ã€æ¥å£äº¤äº’ç­‰ã€‚
æœ€ç»ˆæ ¸å¿ƒæ™ºèƒ½éƒ¨åˆ†æ˜¯é€šè¿‡è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆæœ¬åœ°æˆ–äº‘ç«¯ï¼‰æ¥å®ç°æ¨ç†ã€ç”Ÿæˆã€ç†è§£ç­‰èƒ½åŠ›ã€‚

å¤–å±‚ä»£ç è´Ÿè´£"è¿æ¥"å’Œ"æ§åˆ¶"ï¼Œæ¨¡å‹è´Ÿè´£"æ™ºèƒ½"ã€‚ä¸¤è€…ç»“åˆï¼Œæ‰èƒ½å®ç°å®Œæ•´çš„ AI Agentã€‚

## A2A åè®®ï¼ˆAgent-to-Agent Protocolï¼‰

A2A åè®®æ˜¯ä¸€ç§ç”¨äºå®ç° AI Agent ä¹‹é—´é€šä¿¡å’Œåä½œçš„æ ‡å‡†åŒ–åè®®ã€‚å®ƒå®šä¹‰äº†ä¸åŒ Agent ç³»ç»Ÿä¹‹é—´å¦‚ä½•äº¤æ¢ä¿¡æ¯ã€åè°ƒä»»åŠ¡å’Œå…±äº«èµ„æºã€‚

### æ ¸å¿ƒç‰¹æ€§

1. **æ ‡å‡†åŒ–é€šä¿¡**ï¼šå®šä¹‰ç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼å’Œäº¤äº’è§„èŒƒï¼Œä½¿ä¸åŒå¹³å°ã€ä¸åŒè¯­è¨€å¼€å‘çš„ Agent èƒ½å¤Ÿäº’ç›¸é€šä¿¡
1. **ä»»åŠ¡åè°ƒ**ï¼šæ”¯æŒ Agent ä¹‹é—´çš„ä»»åŠ¡åˆ†é…ã€å§”æ‰˜å’Œç»“æœæ±‡æ€»
1. **èƒ½åŠ›å‘ç°**ï¼šAgent å¯ä»¥æŸ¥è¯¢å’Œå‘ç°å…¶ä»– Agent çš„èƒ½åŠ›å’ŒæœåŠ¡
1. **å®‰å…¨è®¤è¯**ï¼šæä¾›èº«ä»½éªŒè¯å’Œæˆæƒæœºåˆ¶ï¼Œç¡®ä¿é€šä¿¡å®‰å…¨

### ä¸»è¦åº”ç”¨åœºæ™¯

- **å¤š Agent åä½œ**ï¼šå¤šä¸ªä¸“ä¸š Agent ååŒå®Œæˆå¤æ‚ä»»åŠ¡
- **Agent ç¼–æ’**ï¼šæ„å»º Agent å·¥ä½œæµï¼Œå®ç°ä»»åŠ¡çš„è‡ªåŠ¨åŒ–åˆ†å‘å’Œæ‰§è¡Œ
- **è·¨å¹³å°é›†æˆ**ï¼šè¿æ¥ä¸åŒå‚å•†ã€ä¸åŒæŠ€æœ¯æ ˆçš„ Agent ç³»ç»Ÿ
- **åˆ†å¸ƒå¼æ™ºèƒ½**ï¼šåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­å®ç° Agent çš„ååŒå†³ç­–

### ç›¸å…³æŠ€æœ¯æ ‡å‡†

- **MCP (Model Context Protocol)**ï¼šç”¨äº Agent ä¸å·¥å…·/æ•°æ®æºçš„è¿æ¥
- **OpenAI Agents API**ï¼šOpenAI æä¾›çš„ Agent é€šä¿¡æ¥å£
- **LangGraph**ï¼šæ”¯æŒå¤š Agent åä½œçš„ç¼–æ’æ¡†æ¶

A2A åè®®ä½¿å¾—æ„å»ºå¤§è§„æ¨¡ã€å¯æ‰©å±•çš„å¤š Agent ç³»ç»Ÿæˆä¸ºå¯èƒ½ï¼Œæ˜¯ AI Agent ç”Ÿæ€ç³»ç»Ÿä¸­çš„é‡è¦åŸºç¡€è®¾æ–½ã€‚

## VSCode æ‰©å±•æ¡¥æ¥ Copilot æ¨¡å‹

é€šè¿‡ VSCode æ‰©å±•å¯ä»¥å°† GitHub Copilot ä¸­çš„ Claude æ¨¡å‹æ¡¥æ¥å‡ºæ¥ï¼Œä¾›å¤–éƒ¨ AI Agent è°ƒç”¨ã€‚è¿™ç§å®ç°æ–¹å¼ä¸»è¦åŸºäºä»¥ä¸‹æŠ€æœ¯æ–¹æ¡ˆï¼š

### å®ç°åŸç†

1. **VSCode Extension API**
   - ä½¿ç”¨ VSCode æ‰©å±•å¼€å‘æ¡†æ¶åˆ›å»ºè‡ªå®šä¹‰æ‰©å±•
   - é€šè¿‡ `vscode.languages` å’Œ `vscode.commands` API æ³¨å†Œå‘½ä»¤å’ŒæœåŠ¡
   - åˆ©ç”¨ Language Server Protocol (LSP) å®ç°ä¸å¤–éƒ¨é€šä¿¡

2. **GitHub Copilot API è°ƒç”¨**
   - æ‰©å±•å†…éƒ¨é€šè¿‡ Copilot çš„å†…éƒ¨ API è®¿é—® Claude æ¨¡å‹
   - ä½¿ç”¨ `vscode.authentication` è·å– GitHub è®¤è¯ä»¤ç‰Œ
   - è°ƒç”¨ Copilot Chat API å‘é€è¯·æ±‚å¹¶æ¥æ”¶å“åº”

3. **MCP (Model Context Protocol) æœåŠ¡å™¨**
   - åœ¨æ‰©å±•ä¸­å®ç° MCP æœåŠ¡å™¨ï¼Œæš´éœ²æ ‡å‡†åŒ–çš„æ¥å£
   - MCP å®šä¹‰äº†ç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼å’Œé€šä¿¡åè®®
   - æ”¯æŒé€šè¿‡ stdioã€HTTP æˆ– WebSocket ä¸å¤–éƒ¨ Agent é€šä¿¡

### æ ¸å¿ƒå®ç°æ­¥éª¤

1. **åˆ›å»º VSCode æ‰©å±•**

```typescript
// extension.ts
import * as vscode from 'vscode';

export function activate(context: vscode.ExtensionContext) {
  // å¯åŠ¨ MCP æœåŠ¡å™¨
  const mcpServer = new MCPServer();
  mcpServer.start();
  
  // æ³¨å†Œå‘½ä»¤å¤„ç† Copilot è¯·æ±‚
  context.subscriptions.push(
    vscode.commands.registerCommand('extension.queryCopilot', async (prompt) => {
      return await queryCopilotModel(prompt);
    })
  );
}
```

2. **å®ç° MCP æœåŠ¡å™¨**

```typescript
// mcp-server.ts
import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';

class MCPServer {
  private server: Server;
  
  constructor() {
    this.server = new Server({
      name: 'copilot-bridge',
      version: '1.0.0'
    }, {
      capabilities: {
        resources: {},
        tools: {},
        prompts: {}
      }
    });
    
    // æ³¨å†Œå·¥å…·
    this.server.setRequestHandler(ListToolsRequestSchema, async () => ({
      tools: [{
        name: 'query_claude',
        description: 'Query Claude model via Copilot',
        inputSchema: { /* ... */ }
      }]
    }));
  }
  
  async start() {
    const transport = new StdioServerTransport();
    await this.server.connect(transport);
  }
}
```

3. **æ¡¥æ¥ Copilot API**

```typescript
// copilot-bridge.ts
async function queryCopilotModel(prompt: string) {
  // è·å– Copilot Chat API
  const copilot = await vscode.lm.selectChatModels({
    vendor: 'copilot',
    family: 'claude'
  });
  
  // å‘é€è¯·æ±‚
  const messages = [
    vscode.LanguageModelChatMessage.User(prompt)
  ];
  
  const response = await copilot[0].sendRequest(messages);
  
  // æ”¶é›†å“åº”æµ
  let result = '';
  for await (const chunk of response.text) {
    result += chunk;
  }
  
  return result;
}
```

4. **å¤–éƒ¨ Agent è°ƒç”¨**

```python
# external_agent.py
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

async def call_copilot_claude(prompt: str):
    # è¿æ¥åˆ° VSCode æ‰©å±•çš„ MCP æœåŠ¡å™¨
    server_params = StdioServerParameters(
        command="code",
        args=["--extensionDevelopmentPath=/path/to/extension"]
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # åˆå§‹åŒ–è¿æ¥
            await session.initialize()
            
            # è°ƒç”¨å·¥å…·
            result = await session.call_tool("query_claude", {
                "prompt": prompt
            })
            
            return result
```

### å…³é”®æŠ€æœ¯ç‚¹

1. **è®¤è¯ä¸æƒé™**
   - åˆ©ç”¨ VSCode çš„ GitHub è®¤è¯çŠ¶æ€
   - æ‰©å±•è¿è¡Œåœ¨ VSCode è¿›ç¨‹ä¸­ï¼Œè‡ªåŠ¨ç»§æ‰¿ Copilot è®¢é˜…æƒé™

2. **é€šä¿¡æ–¹å¼**
   - **Stdio**ï¼šæœ€ç®€å•ï¼Œé€šè¿‡æ ‡å‡†è¾“å…¥è¾“å‡ºé€šä¿¡
   - **HTTP Server**ï¼šæ‰©å±•å¯åŠ¨ HTTP æœåŠ¡å™¨ï¼Œå¤–éƒ¨é€šè¿‡ REST API è°ƒç”¨
   - **WebSocket**ï¼šæ”¯æŒåŒå‘å®æ—¶é€šä¿¡

3. **æ¶ˆæ¯åºåˆ—åŒ–**
   - ä½¿ç”¨ JSON-RPC 2.0 åè®®
   - MCP å®šä¹‰äº†æ ‡å‡†çš„è¯·æ±‚/å“åº”æ ¼å¼
   - æ”¯æŒæµå¼å“åº”ï¼ˆSSEï¼‰

### ä¼˜åŠ¿

- **å¤ç”¨è®¤è¯**ï¼šæ— éœ€å•ç‹¬é…ç½® API Key
- **æˆæœ¬èŠ‚çœ**ï¼šä½¿ç”¨å·²æœ‰çš„ Copilot è®¢é˜…
- **ç»Ÿä¸€æ¥å£**ï¼šé€šè¿‡ MCP æä¾›æ ‡å‡†åŒ–æ¥å£
- **å®‰å…¨éš”ç¦»**ï¼šæ‰©å±•è¿è¡Œåœ¨ VSCode æ²™ç®±ä¸­

### ç›¸å…³é¡¹ç›®

- **MCP SDK**ï¼š`@modelcontextprotocol/sdk` - MCP åè®®å®ç°
- **VSCode Extension API**ï¼šVSCode æ‰©å±•å¼€å‘æ¡†æ¶
- **Language Model API**ï¼š`vscode.lm` - VSCode è¯­è¨€æ¨¡å‹æ¥å£

è¿™ç§æ¡¥æ¥æ–¹æ¡ˆä½¿å¾—å¼€å‘è€…å¯ä»¥åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä¸­ï¼Œé€šè¿‡ç»Ÿä¸€çš„ MCP æ¥å£è°ƒç”¨å¤šç§ AI æ¨¡å‹ï¼ŒåŒ…æ‹¬ GitHub Copilot æä¾›çš„ Claudeã€GPT ç­‰æ¨¡å‹ã€‚

## AI Agent çš„æ„å›¾è¯†åˆ«ä¸å·¥å…·è°ƒç”¨

AI Agent çš„ä¸€ä¸ªæ ¸å¿ƒåº”ç”¨åœºæ™¯æ˜¯**è‡ªç„¶è¯­è¨€ç†è§£ â†’ æ„å›¾è¯†åˆ« â†’ å·¥å…·è°ƒç”¨**ã€‚è¿™æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª**åˆ†ç±»é—®é¢˜**ï¼Œå³å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥åˆ†ç±»åˆ°ä¸åŒçš„æ„å›¾ç±»åˆ«ï¼Œç„¶åè·¯ç”±åˆ°ç›¸åº”çš„å·¥å…·æ‰§è¡Œå…·ä½“ä»»åŠ¡ã€‚

### å·¥ä½œæµç¨‹

1. **è‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰**
   - ç”¨æˆ·è¾“å…¥ï¼šè‡ªç„¶è¯­è¨€æŸ¥è¯¢æˆ–æŒ‡ä»¤
   - Agent ä½¿ç”¨ LLM ç†è§£è¯­ä¹‰å’Œä¸Šä¸‹æ–‡

2. **æ„å›¾è¯†åˆ«ï¼ˆIntent Recognitionï¼‰**
   - **LLM çš„æ ¸å¿ƒä½œç”¨**ï¼šç†è§£è‡ªç„¶è¯­è¨€å¹¶æ˜ å°„åˆ°é¢„å®šä¹‰çš„æ„å›¾åˆ†ç±»
   - å°†ç”¨æˆ·è¾“å…¥åˆ†ç±»åˆ°é¢„å®šä¹‰çš„æ„å›¾ç±»åˆ«
   - ä¾‹å¦‚ï¼šæŸ¥è¯¢å¤©æ°”ã€é¢„è®¢é¤å…ã€å‘é€é‚®ä»¶ã€æŸ¥è¯¢æ•°æ®åº“ç­‰
   - è¿™æ˜¯ä¸€ä¸ª**å¤šåˆ†ç±»ä»»åŠ¡**

3. **å‚æ•°æå–ï¼ˆSlot Fillingï¼‰**
   - **LLM çš„ç¬¬äºŒä¸ªä½œç”¨**ï¼šä»è‡ªç„¶è¯­è¨€ä¸­æå–å…³é”®å‚æ•°ä¾›å·¥å…·ä½¿ç”¨
   - ä»ç”¨æˆ·è¾“å…¥ä¸­æå–å…³é”®å‚æ•°
   - ä¾‹å¦‚ï¼š"æ˜å¤©åŒ—äº¬çš„å¤©æ°”" â†’ æ—¶é—´=æ˜å¤©, åœ°ç‚¹=åŒ—äº¬
   - LLM èƒ½ç†è§£å„ç§è‡ªç„¶è¯­è¨€è¡¨è¾¾æ–¹å¼å¹¶æå–ç»“æ„åŒ–å‚æ•°

4. **å·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰**
   - æ ¹æ®è¯†åˆ«çš„æ„å›¾ï¼Œè°ƒç”¨å¯¹åº”çš„é¢„å¼€å‘å·¥å…·æˆ–å‡½æ•°
   - ä¼ é€’æå–çš„å‚æ•°ç»™å·¥å…·
   - è·å–å·¥å…·æ‰§è¡Œç»“æœ

5. **ç»“æœç»„ç»‡ä¸è¿”å›**
   - å°†å·¥å…·è¿”å›çš„ç»“æœç»„ç»‡æˆè‡ªç„¶è¯­è¨€
   - è¿”å›ç»™ç”¨æˆ·

### å®ç°ç¤ºä¾‹

```python
# æ„å›¾è¯†åˆ«ä¸å·¥å…·è°ƒç”¨ç¤ºä¾‹
class IntentBasedAgent:
    def __init__(self, llm):
        self.llm = llm
        self.tools = {
            "weather": get_weather_tool,
            "email": send_email_tool,
            "database": query_database_tool,
            "calendar": schedule_meeting_tool
        }
    
    async def process(self, user_input: str):
        # 1. æ„å›¾è¯†åˆ«ï¼ˆåˆ†ç±»ï¼‰
        intent_prompt = f"""
        åˆ†æç”¨æˆ·æ„å›¾ï¼Œè¿”å›æ„å›¾ç±»åˆ«å’Œå‚æ•°ï¼š
        ç”¨æˆ·è¾“å…¥ï¼š{user_input}
        
        å¯é€‰æ„å›¾ï¼šweather, email, database, calendar
        è¿”å› JSON æ ¼å¼ï¼š{{"intent": "...", "params": {{...}}}}
        """
        
        response = await self.llm.query(intent_prompt)
        intent_data = json.loads(response)
        
        intent = intent_data["intent"]
        params = intent_data["params"]
        
        # 2. æ ¹æ®æ„å›¾è°ƒç”¨ç›¸åº”å·¥å…·
        if intent in self.tools:
            tool = self.tools[intent]
            result = await tool(**params)
            return result
        else:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç†è§£æ‚¨çš„æ„å›¾"

# ä½¿ç”¨ç¤ºä¾‹
agent = IntentBasedAgent(llm)

# ç”¨æˆ·è¾“å…¥ï¼š"æŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”"
# æ„å›¾è¯†åˆ«ç»“æœï¼šintent="weather", params={"date": "æ˜å¤©", "city": "åŒ—äº¬"}
# è°ƒç”¨å·¥å…·ï¼šget_weather_tool(date="æ˜å¤©", city="åŒ—äº¬")
```

### æ„å›¾è¯†åˆ«çš„å®ç°æ–¹å¼

#### 1. **åŸºäº LLM çš„æ„å›¾è¯†åˆ«**ï¼ˆæ¨èï¼‰

```python
# ä½¿ç”¨ Function Calling / Tool Use
tools_schema = [
    {
        "name": "get_weather",
        "description": "æŸ¥è¯¢å¤©æ°”ä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "åŸå¸‚åç§°"},
                "date": {"type": "string", "description": "æ—¥æœŸ"}
            }
        }
    },
    {
        "name": "send_email",
        "description": "å‘é€é‚®ä»¶",
        "parameters": {
            "type": "object",
            "properties": {
                "to": {"type": "string"},
                "subject": {"type": "string"},
                "body": {"type": "string"}
            }
        }
    }
]

# LLM è‡ªåŠ¨è¯†åˆ«æ„å›¾å¹¶è¿”å›åº”è°ƒç”¨çš„å·¥å…·
response = llm.chat(
    messages=[{"role": "user", "content": user_input}],
    tools=tools_schema
)

# LLM è¿”å›ï¼štool_call = {"name": "get_weather", "arguments": {"city": "åŒ—äº¬", "date": "æ˜å¤©"}}
```

#### 2. **ä¼ ç»Ÿåˆ†ç±»æ¨¡å‹**ï¼ˆè½»é‡çº§åœºæ™¯ï¼‰

```python
# ä½¿ç”¨æ–‡æœ¬åˆ†ç±»æ¨¡å‹
from transformers import pipeline

classifier = pipeline("text-classification", model="intent-classifier")
result = classifier("æŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”")
# è¾“å‡ºï¼š{"label": "weather", "score": 0.95}
```

#### 3. **åŸºäºè§„åˆ™çš„æ„å›¾è¯†åˆ«**ï¼ˆç®€å•åœºæ™¯ï¼‰

```python
# å…³é”®è¯åŒ¹é…
intent_patterns = {
    "weather": ["å¤©æ°”", "æ¸©åº¦", "ä¸‹é›¨"],
    "email": ["å‘é‚®ä»¶", "å‘é€é‚®ä»¶", "å†™é‚®ä»¶"],
    "database": ["æŸ¥è¯¢", "æ•°æ®", "ç»Ÿè®¡"]
}

def match_intent(user_input):
    for intent, keywords in intent_patterns.items():
        if any(kw in user_input for kw in keywords):
            return intent
    return "unknown"
```

### æ ¸å¿ƒä¼˜åŠ¿

1. **è§£è€¦è®¾è®¡**
   - æ„å›¾è¯†åˆ«å±‚ä¸å·¥å…·æ‰§è¡Œå±‚åˆ†ç¦»
   - æ˜“äºç»´æŠ¤å’Œæ‰©å±•æ–°å·¥å…·

2. **å¯æ‰©å±•æ€§**
   - æ·»åŠ æ–°æ„å›¾åªéœ€æ³¨å†Œæ–°å·¥å…·
   - ä¸éœ€è¦ä¿®æ”¹æ ¸å¿ƒé€»è¾‘

3. **çµæ´»æ€§**
   - æ”¯æŒå¤šè½®å¯¹è¯ï¼ˆè¿½é—®å‚æ•°ï¼‰
   - æ”¯æŒæ„å›¾åˆ‡æ¢å’Œä¸Šä¸‹æ–‡ç®¡ç†

4. **å¯æ§æ€§**
   - æ˜ç¡®çš„æ„å›¾åˆ†ç±»è¾¹ç•Œ
   - ä¾¿äºç›‘æ§å’Œè°ƒè¯•

### å®é™…åº”ç”¨æ¡ˆä¾‹

- **æ™ºèƒ½å®¢æœ**ï¼šè¯†åˆ«ç”¨æˆ·å’¨è¯¢æ„å›¾ï¼ˆé€€æ¬¾ã€æŸ¥è¯¢è®¢å•ã€æŠ•è¯‰ç­‰ï¼‰
- **ä¸ªäººåŠ©æ‰‹**ï¼šè¯†åˆ«æ—¥ç¨‹ç®¡ç†ã€é‚®ä»¶ã€æé†’ç­‰æ„å›¾
- **å¼€å‘å·¥å…·**ï¼šè¯†åˆ«ä»£ç ç”Ÿæˆã€bug ä¿®å¤ã€é‡æ„ç­‰æ„å›¾ï¼ˆå¦‚ GitHub Copilotï¼‰
- **ä¼ä¸šç³»ç»Ÿ**ï¼šè¯†åˆ«æŸ¥è¯¢æŠ¥è¡¨ã€å®¡æ‰¹æµç¨‹ã€æ•°æ®åˆ†æç­‰æ„å›¾

### æ€»ç»“

æ„å›¾è¯†åˆ«æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª**åˆ†ç±»ä»»åŠ¡**ï¼Œå°†ç”¨æˆ·è¾“å…¥æ˜ å°„åˆ°é¢„å®šä¹‰çš„å·¥å…·é›†åˆã€‚**LLM åœ¨è¿™é‡Œæ‰®æ¼”åŒé‡è§’è‰²**ï¼š

1. **æ™ºèƒ½åˆ†ç±»å™¨**ï¼šç†è§£è‡ªç„¶è¯­è¨€å¹¶æ˜ å°„åˆ°é¢„å®šä¹‰çš„æ„å›¾ç±»åˆ«
2. **å‚æ•°æå–å™¨**ï¼šä»è‡ªç„¶è¯­è¨€ä¸­æå–å…³é”®ä¿¡æ¯å¹¶è½¬æ¢ä¸ºç»“æ„åŒ–å‚æ•°ä¾›å·¥å…·ä½¿ç”¨

ä¾‹å¦‚ï¼š"å¸®æˆ‘æŸ¥ä¸€ä¸‹æ˜å¤©åŒ—äº¬çš„å¤©æ°”"
- åˆ†ç±»ï¼šè¯†åˆ«æ„å›¾ä¸º `get_weather`
- æå–å‚æ•°ï¼š`{"date": "æ˜å¤©", "city": "åŒ—äº¬"}`

ç°ä»£ AI Agent é€šå¸¸ä½¿ç”¨ LLM çš„ Function Calling èƒ½åŠ›æ¥**åŒæ—¶å®Œæˆ**æ„å›¾è¯†åˆ«å’Œå‚æ•°æå–ä¸¤ä¸ªä»»åŠ¡ï¼Œè¿™æ¯”ä¼ ç»Ÿçš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹æ›´çµæ´»ã€æ›´å‡†ç¡®ï¼Œèƒ½å¤Ÿç†è§£å„ç§è‡ªç„¶è¯­è¨€è¡¨è¾¾æ–¹å¼ã€‚

## Slot Fillingï¼ˆæ§½ä½å¡«å……ï¼‰è¯¦è§£

Slot Filling æ˜¯ NLUï¼ˆè‡ªç„¶è¯­è¨€ç†è§£ï¼‰ä¸­çš„å…³é”®æŠ€æœ¯ï¼Œç”¨äºä»ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¡«å……åˆ°é¢„å®šä¹‰çš„"æ§½ä½"ä¸­ï¼Œä¸ºåç»­çš„å·¥å…·è°ƒç”¨æä¾›å¿…è¦çš„å‚æ•°ã€‚

### æ ¸å¿ƒæ¦‚å¿µ

**æ§½ä½ï¼ˆSlotï¼‰**ï¼šé¢„å®šä¹‰çš„å‚æ•°å­—æ®µï¼Œä»£è¡¨å®ŒæˆæŸä¸ªä»»åŠ¡æ‰€éœ€çš„å…³é”®ä¿¡æ¯ã€‚

ä¾‹å¦‚ï¼Œå¯¹äº"æŸ¥è¯¢å¤©æ°”"è¿™ä¸ªæ„å›¾ï¼š
- å¿…å¡«æ§½ä½ï¼š`city`ï¼ˆåŸå¸‚ï¼‰
- å¯é€‰æ§½ä½ï¼š`date`ï¼ˆæ—¥æœŸï¼‰ã€`time`ï¼ˆæ—¶é—´ï¼‰

### å·¥ä½œåŸç†

```
ç”¨æˆ·è¾“å…¥ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ â†’ Slot Filling â†’ ç»“æ„åŒ–å‚æ•° â†’ å·¥å…·è°ƒç”¨
```

**ç¤ºä¾‹ 1ï¼šå®Œæ•´ä¿¡æ¯**
```
è¾“å…¥ï¼š"æŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”"
æ§½ä½æå–ï¼š
  - intent: "get_weather"
  - city: "åŒ—äº¬"
  - date: "æ˜å¤©"
  
å·¥å…·è°ƒç”¨ï¼šget_weather(city="åŒ—äº¬", date="æ˜å¤©")
```

**ç¤ºä¾‹ 2ï¼šç¼ºå¤±ä¿¡æ¯ï¼ˆéœ€è¦è¿½é—®ï¼‰**
```
è¾“å…¥ï¼š"æŸ¥è¯¢æ˜å¤©çš„å¤©æ°”"
æ§½ä½æå–ï¼š
  - intent: "get_weather"
  - city: null  # å¿…å¡«æ§½ä½ç¼ºå¤±
  - date: "æ˜å¤©"
  
Agent è¿½é—®ï¼š"è¯·é—®æ‚¨è¦æŸ¥è¯¢å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿ"
ç”¨æˆ·å›ç­”ï¼š"åŒ—äº¬"
è¡¥å……æ§½ä½ï¼šcity: "åŒ—äº¬"
å·¥å…·è°ƒç”¨ï¼šget_weather(city="åŒ—äº¬", date="æ˜å¤©")
```

### å®ç°æ–¹å¼

#### 1. **åŸºäº LLM çš„ Slot Filling**ï¼ˆæ¨èï¼‰

```python
# ä½¿ç”¨ LLM è‡ªåŠ¨æå–æ§½ä½
slot_extraction_prompt = """
ä»ç”¨æˆ·è¾“å…¥ä¸­æå–ä»¥ä¸‹ä¿¡æ¯ï¼š
- åŸå¸‚ï¼ˆcityï¼‰
- æ—¥æœŸï¼ˆdateï¼‰
- æ—¶é—´ï¼ˆtimeï¼‰

ç”¨æˆ·è¾“å…¥ï¼š{user_input}

è¿”å› JSON æ ¼å¼ï¼š{{"city": "...", "date": "...", "time": "..."}}
å¦‚æœæŸä¸ªä¿¡æ¯æœªæåŠï¼Œè¿”å› nullã€‚
"""

# LLM å¤„ç†
user_input = "å¸®æˆ‘æŸ¥ä¸€ä¸‹åå¤©ä¸Šæµ·çš„å¤©æ°”"
response = llm.query(slot_extraction_prompt.format(user_input=user_input))
slots = json.loads(response)
# ç»“æœï¼š{"city": "ä¸Šæµ·", "date": "åå¤©", "time": null}
```

#### 2. **ä½¿ç”¨ Function Callingï¼ˆæœ€å…ˆè¿›ï¼‰**

```python
# OpenAI Function Calling ç¤ºä¾‹
function_schema = {
    "name": "get_weather",
    "description": "æŸ¥è¯¢å¤©æ°”ä¿¡æ¯",
    "parameters": {
        "type": "object",
        "properties": {
            "city": {
                "type": "string",
                "description": "åŸå¸‚åç§°"
            },
            "date": {
                "type": "string",
                "description": "æ—¥æœŸï¼Œå¦‚'ä»Šå¤©'ã€'æ˜å¤©'ã€'2025-11-20'"
            }
        },
        "required": ["city"]  # å¿…å¡«æ§½ä½
    }
}

# LLM è‡ªåŠ¨æå–å¹¶éªŒè¯æ§½ä½
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "æ˜å¤©åŒ—äº¬ä¼šä¸‹é›¨å—"}],
    functions=[function_schema],
    function_call="auto"
)

# LLM è‡ªåŠ¨è¿”å›ï¼š
# {
#   "name": "get_weather",
#   "arguments": {
#     "city": "åŒ—äº¬",
#     "date": "æ˜å¤©"
#   }
# }
```

#### 3. **ä¼ ç»Ÿåºåˆ—æ ‡æ³¨æ–¹æ³•**

```python
# ä½¿ç”¨ NERï¼ˆå‘½åå®ä½“è¯†åˆ«ï¼‰+ è§„åˆ™
from transformers import pipeline

ner = pipeline("ner", model="bert-base-chinese-ner")
text = "æŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”"
entities = ner(text)

# è¾“å‡ºï¼š
# [
#   {"entity": "TIME", "word": "æ˜å¤©"},
#   {"entity": "LOC", "word": "åŒ—äº¬"}
# ]

# æ˜ å°„åˆ°æ§½ä½
slots = {
    "date": "æ˜å¤©",  # TIME â†’ date
    "city": "åŒ—äº¬"   # LOC â†’ city
}
```

### å¤šè½®å¯¹è¯ä¸æ§½ä½è¡¥å…¨

å½“å¿…å¡«æ§½ä½ç¼ºå¤±æ—¶ï¼ŒAgent éœ€è¦ä¸»åŠ¨è¿½é—®ï¼š

```python
class SlotFillingAgent:
    def __init__(self):
        self.slots = {
            "city": None,
            "date": None
        }
        self.required_slots = ["city"]
    
    def process(self, user_input):
        # æå–æ§½ä½
        extracted = extract_slots(user_input)
        self.slots.update(extracted)
        
        # æ£€æŸ¥å¿…å¡«æ§½ä½
        missing = [s for s in self.required_slots if not self.slots[s]]
        
        if missing:
            # æ§½ä½ç¼ºå¤±ï¼Œè¿½é—®
            return self.ask_for_slot(missing[0])
        else:
            # æ§½ä½å®Œæ•´ï¼Œæ‰§è¡Œå·¥å…·è°ƒç”¨
            return self.call_tool()
    
    def ask_for_slot(self, slot_name):
        questions = {
            "city": "è¯·é—®æ‚¨è¦æŸ¥è¯¢å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿ",
            "date": "è¯·é—®æ‚¨è¦æŸ¥è¯¢å“ªå¤©çš„å¤©æ°”ï¼Ÿ"
        }
        return questions.get(slot_name)
    
    def call_tool(self):
        return get_weather(**self.slots)

# ä½¿ç”¨ç¤ºä¾‹
agent = SlotFillingAgent()

# ç¬¬ä¸€è½®
response1 = agent.process("æŸ¥æ˜å¤©çš„å¤©æ°”")
print(response1)  # "è¯·é—®æ‚¨è¦æŸ¥è¯¢å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿ"

# ç¬¬äºŒè½®
response2 = agent.process("åŒ—äº¬")
print(response2)  # è¿”å›å¤©æ°”ä¿¡æ¯
```

### æ§½ä½ç±»å‹

1. **å¿…å¡«æ§½ä½ï¼ˆRequired Slotsï¼‰**
   - å®Œæˆä»»åŠ¡å¿…é¡»çš„å‚æ•°
   - ç¼ºå¤±æ—¶éœ€è¦è¿½é—®ç”¨æˆ·

2. **å¯é€‰æ§½ä½ï¼ˆOptional Slotsï¼‰**
   - å¯ä»¥æœ‰é»˜è®¤å€¼æˆ–çœç•¥
   - ä¾‹å¦‚ï¼šdate é»˜è®¤ä¸º"ä»Šå¤©"

3. **ä¾èµ–æ§½ä½ï¼ˆDependent Slotsï¼‰**
   - ä¾èµ–äºå…¶ä»–æ§½ä½çš„å€¼
   - ä¾‹å¦‚ï¼šé€‰æ‹©"ç«è½¦ç¥¨"åæ‰éœ€è¦"è½¦æ¬¡å·"

### æ§½ä½æ ‡å‡†åŒ–

LLM æå–çš„æ§½ä½å€¼éœ€è¦æ ‡å‡†åŒ–å¤„ç†ï¼š

```python
def normalize_slots(slots):
    """æ ‡å‡†åŒ–æ§½ä½å€¼"""
    # æ—¶é—´æ ‡å‡†åŒ–
    if slots.get("date"):
        slots["date"] = normalize_date(slots["date"])
        # "æ˜å¤©" â†’ "2025-11-20"
        # "åå¤©" â†’ "2025-11-21"
    
    # åœ°ç‚¹æ ‡å‡†åŒ–
    if slots.get("city"):
        slots["city"] = normalize_city(slots["city"])
        # "å¸éƒ½" â†’ "åŒ—äº¬"
        # "é­”éƒ½" â†’ "ä¸Šæµ·"
    
    return slots
```

### ä¼˜åŠ¿ä¸æŒ‘æˆ˜

**ä¼˜åŠ¿**ï¼š
- å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®
- æ”¯æŒçµæ´»çš„è¡¨è¾¾æ–¹å¼
- å¯ä»¥é€šè¿‡å¤šè½®å¯¹è¯è¡¥å…¨ä¿¡æ¯

**æŒ‘æˆ˜**ï¼š
- æ­§ä¹‰æ¶ˆè§£ï¼ˆ"è‹¹æœ"æ˜¯æ°´æœè¿˜æ˜¯å…¬å¸ï¼Ÿï¼‰
- éšå¼ä¿¡æ¯æå–ï¼ˆ"å»é‚£é‡Œ"ä¸­çš„"é‚£é‡Œ"æŒ‡å“ªé‡Œï¼Ÿï¼‰
- ä¸Šä¸‹æ–‡ä¾èµ–ï¼ˆéœ€è¦è®°ä½å¯¹è¯å†å²ï¼‰

### å®é™…åº”ç”¨

- **æ™ºèƒ½å®¢æœ**ï¼šè®¢å•å·ã€é—®é¢˜ç±»å‹ã€è”ç³»æ–¹å¼
- **è¯­éŸ³åŠ©æ‰‹**ï¼šé—¹é’Ÿæ—¶é—´ã€æé†’å†…å®¹ã€é‡å¤è§„åˆ™
- **æ—…è¡Œé¢„è®¢**ï¼šå‡ºå‘åœ°ã€ç›®çš„åœ°ã€æ—¥æœŸã€äººæ•°
- **é¤å…é¢„è®¢**ï¼šé¤å…åç§°ã€å°±é¤æ—¶é—´ã€äººæ•°

Slot Filling æ˜¯è¿æ¥è‡ªç„¶è¯­è¨€å’Œç»“æ„åŒ–å·¥å…·è°ƒç”¨çš„å…³é”®æ¡¥æ¢ï¼Œç°ä»£ LLM çš„å‡ºç°ä½¿å¾—è¿™ä¸€è¿‡ç¨‹å˜å¾—æ›´åŠ æ™ºèƒ½å’Œçµæ´»ã€‚

## Function Callingï¼ˆå‡½æ•°è°ƒç”¨ï¼‰è¯¦è§£

Function Calling æ˜¯ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPT-4ã€Claudeï¼‰æä¾›çš„ä¸€é¡¹é«˜çº§èƒ½åŠ›ï¼Œå…è®¸ LLM è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·æ„å›¾ã€æå–å‚æ•°ï¼Œå¹¶ç”Ÿæˆæ ‡å‡†åŒ–çš„å‡½æ•°è°ƒç”¨è¯·æ±‚ã€‚å®ƒæ˜¯ AI Agent å®ç°å·¥å…·è°ƒç”¨çš„æœ€å…ˆè¿›æ–¹å¼ã€‚

### ä»€ä¹ˆæ˜¯ Function Calling

Function Calling æ˜¯ LLM çš„ä¸€ç§ç‰¹æ®Šè¾“å‡ºæ¨¡å¼ï¼šä¸æ˜¯ç›´æ¥è¿”å›æ–‡æœ¬ï¼Œè€Œæ˜¯è¿”å›ä¸€ä¸ª**ç»“æ„åŒ–çš„å‡½æ•°è°ƒç”¨æŒ‡ä»¤**ï¼ŒåŒ…å«ï¼š
- è¦è°ƒç”¨çš„å‡½æ•°åç§°
- å‡½æ•°æ‰€éœ€çš„å‚æ•°ï¼ˆJSON æ ¼å¼ï¼‰

**æ ¸å¿ƒæµç¨‹**ï¼š
```
ç”¨æˆ·è¾“å…¥ â†’ LLM åˆ†æ â†’ è¿”å›å‡½æ•°è°ƒç”¨æŒ‡ä»¤ â†’ æ‰§è¡Œå‡½æ•° â†’ è¿”å›ç»“æœ â†’ LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€å“åº”
```

### Function Calling vs ä¼ ç»Ÿ Slot Filling

#### ä¼ ç»Ÿ Slot Filling çš„å±€é™

1. **éœ€è¦å¤šæ­¥å¤„ç†**
   ```
   æ­¥éª¤1ï¼šæ„å›¾è¯†åˆ«ï¼ˆè°ƒç”¨ä¸€æ¬¡ LLMï¼‰
   æ­¥éª¤2ï¼šå‚æ•°æå–ï¼ˆå†è°ƒç”¨ä¸€æ¬¡ LLM æˆ–ä½¿ç”¨ NERï¼‰
   æ­¥éª¤3ï¼šæ‰‹åŠ¨ç»„è£…å‡½æ•°è°ƒç”¨
   ```

2. **å®¹æ˜“å‡ºé”™**
   - æ„å›¾è¯†åˆ«å¯èƒ½ä¸å‡†ç¡®
   - å‚æ•°æå–å¯èƒ½é—æ¼æˆ–é”™è¯¯
   - éœ€è¦é¢å¤–çš„æ•°æ®éªŒè¯é€»è¾‘

3. **å¼€å‘æˆæœ¬é«˜**
   - éœ€è¦ç¼–å†™æ„å›¾è¯†åˆ«é€»è¾‘
   - éœ€è¦ç¼–å†™å‚æ•°æå–å’ŒéªŒè¯ä»£ç 
   - éœ€è¦ç»´æŠ¤å¤šä¸ªå¤„ç†æ­¥éª¤

#### Function Calling çš„ä¼˜åŠ¿

1. **ä¸€æ­¥åˆ°ä½**
   ```
   ç”¨æˆ·è¾“å…¥ â†’ LLM â†’ ç›´æ¥è¿”å›å®Œæ•´çš„å‡½æ•°è°ƒç”¨ï¼ˆåŒ…å«æ„å›¾å’Œå‚æ•°ï¼‰
   ```

2. **å†…ç½®éªŒè¯**
   - LLM æ ¹æ®å‡½æ•°å®šä¹‰çš„ schema è‡ªåŠ¨éªŒè¯å‚æ•°
   - è‡ªåŠ¨å¤„ç†ç±»å‹è½¬æ¢
   - è‡ªåŠ¨è¯†åˆ«å¿…å¡«å’Œå¯é€‰å‚æ•°

3. **å¤šå‡½æ•°é€‰æ‹©**
   - LLM å¯ä»¥ä»å¤šä¸ªå¯ç”¨å‡½æ•°ä¸­æ™ºèƒ½é€‰æ‹©
   - æ”¯æŒå¹¶è¡Œè°ƒç”¨å¤šä¸ªå‡½æ•°
   - è‡ªåŠ¨å¤„ç†å‡½æ•°ä¾èµ–å…³ç³»

4. **å¼€å‘æ•ˆç‡é«˜**
   - åªéœ€å®šä¹‰å‡½æ•° schema
   - LLM è‡ªåŠ¨å®Œæˆæ„å›¾è¯†åˆ«å’Œå‚æ•°æå–
   - å‡å°‘å¤§é‡èƒ¶æ°´ä»£ç 

### å®ç°ç¤ºä¾‹å¯¹æ¯”

#### ä¼ ç»Ÿ Slot Filling å®ç°

```python
# æ­¥éª¤1ï¼šæ„å›¾è¯†åˆ«
intent_prompt = "ç”¨æˆ·è¯´ï¼š'æ˜å¤©åŒ—äº¬ä¼šä¸‹é›¨å—'ï¼Œæ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿè¿”å›ï¼šweather/email/calendar"
intent = llm.query(intent_prompt)  # è¿”å› "weather"

# æ­¥éª¤2ï¼šå‚æ•°æå–
slot_prompt = "ä»'æ˜å¤©åŒ—äº¬ä¼šä¸‹é›¨å—'ä¸­æå–ï¼šåŸå¸‚ã€æ—¥æœŸã€‚è¿”å›JSON"
slots = json.loads(llm.query(slot_prompt))  # {"city": "åŒ—äº¬", "date": "æ˜å¤©"}

# æ­¥éª¤3ï¼šæ‰‹åŠ¨éªŒè¯å’Œè°ƒç”¨
if intent == "weather":
    if "city" not in slots:
        return "è¯·æä¾›åŸå¸‚åç§°"
    result = get_weather(city=slots["city"], date=slots.get("date"))
```

#### Function Calling å®ç°

```python
# ä¸€æ¬¡æ€§å®Œæˆï¼
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "æŸ¥è¯¢å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°"
                    },
                    "date": {
                        "type": "string",
                        "description": "æ—¥æœŸ",
                        "default": "ä»Šå¤©"
                    }
                },
                "required": ["city"]
            }
        }
    }
]

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "æ˜å¤©åŒ—äº¬ä¼šä¸‹é›¨å—"}],
    tools=tools,
    tool_choice="auto"
)

# LLM è‡ªåŠ¨è¿”å›ï¼š
# {
#   "tool_calls": [{
#     "function": {
#       "name": "get_weather",
#       "arguments": '{"city": "åŒ—äº¬", "date": "æ˜å¤©"}'
#     }
#   }]
# }

# ç›´æ¥æ‰§è¡Œ
tool_call = response.choices[0].message.tool_calls[0]
result = get_weather(**json.loads(tool_call.function.arguments))
```

### Function Calling çš„é«˜çº§ç‰¹æ€§

#### 1. **å¤šå·¥å…·å¹¶è¡Œè°ƒç”¨**

```python
# ç”¨æˆ·ï¼š"æŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”ï¼Œå¹¶ç»™å¼ ä¸‰å‘é‚®ä»¶é€šçŸ¥"
# LLM è‡ªåŠ¨è¯†åˆ«éœ€è¦è°ƒç”¨ä¸¤ä¸ªå‡½æ•°
response = {
    "tool_calls": [
        {
            "function": {
                "name": "get_weather",
                "arguments": '{"city": "åŒ—äº¬", "date": "æ˜å¤©"}'
            }
        },
        {
            "function": {
                "name": "send_email",
                "arguments": '{"to": "zhangsan@example.com", "subject": "å¤©æ°”é€šçŸ¥"}'
            }
        }
    ]
}
```

#### 2. **æ™ºèƒ½å‚æ•°æ¨æ–­**

```python
# ç”¨æˆ·ï¼š"é‚£é‡Œæ˜å¤©ä¼šä¸‹é›¨å—ï¼Ÿ"ï¼ˆä¸Šä¸‹æ–‡ï¼šä¹‹å‰æåˆ°åŒ—äº¬ï¼‰
# LLM è‡ªåŠ¨ä»å¯¹è¯å†å²æ¨æ–­å‚æ•°
response = {
    "tool_calls": [{
        "function": {
            "name": "get_weather",
            "arguments": '{"city": "åŒ—äº¬", "date": "æ˜å¤©"}'  # è‡ªåŠ¨æ¨æ–­ city
        }
    }]
}
```

#### 3. **ç±»å‹è‡ªåŠ¨è½¬æ¢**

```python
# ç”¨æˆ·ï¼š"æé†’æˆ‘3å°æ—¶åå¼€ä¼š"
# LLM è‡ªåŠ¨å°†"3å°æ—¶å"è½¬æ¢ä¸ºæ­£ç¡®çš„æ—¶é—´æ ¼å¼
response = {
    "tool_calls": [{
        "function": {
            "name": "set_reminder",
            "arguments": '{"time": "2025-11-19T11:30:00", "message": "å¼€ä¼š"}'
        }
    }]
}
```

### ä¸ºä»€ä¹ˆ Function Calling æ›´å…ˆè¿›

| ç»´åº¦ | ä¼ ç»Ÿ Slot Filling | Function Calling |
|-----|------------------|------------------|
| **å¤„ç†æ­¥éª¤** | å¤šæ­¥ï¼ˆæ„å›¾è¯†åˆ« â†’ å‚æ•°æå– â†’ éªŒè¯ï¼‰ | ä¸€æ­¥å®Œæˆ |
| **å‡†ç¡®æ€§** | æ¯ä¸€æ­¥éƒ½å¯èƒ½å‡ºé”™ | LLM ç«¯åˆ°ç«¯ä¿è¯å‡†ç¡®æ€§ |
| **å‚æ•°éªŒè¯** | éœ€è¦æ‰‹åŠ¨ç¼–å†™éªŒè¯ä»£ç  | åŸºäº JSON Schema è‡ªåŠ¨éªŒè¯ |
| **å¤šå·¥å…·é€‰æ‹©** | éœ€è¦å¤æ‚çš„è·¯ç”±é€»è¾‘ | LLM è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…· |
| **ä¸Šä¸‹æ–‡ç†è§£** | éš¾ä»¥åˆ©ç”¨å¯¹è¯å†å² | è‡ªåŠ¨åˆ©ç”¨ä¸Šä¸‹æ–‡æ¨æ–­å‚æ•° |
| **å¹¶è¡Œè°ƒç”¨** | éœ€è¦æ‰‹åŠ¨ç¼–æ’ | è‡ªåŠ¨è¯†åˆ«å¹¶è¡Œä»»åŠ¡ |
| **å¼€å‘æˆæœ¬** | é«˜ï¼ˆå¤§é‡èƒ¶æ°´ä»£ç ï¼‰ | ä½ï¼ˆåªéœ€å®šä¹‰ schemaï¼‰ |
| **ç»´æŠ¤æˆæœ¬** | é«˜ï¼ˆå¤šä¸ªç¯èŠ‚éœ€è¦ç»´æŠ¤ï¼‰ | ä½ï¼ˆé›†ä¸­åœ¨å‡½æ•°å®šä¹‰ï¼‰ |

### å®Œæ•´ç¤ºä¾‹ï¼šå¤©æ°”åŠ©æ‰‹

```python
import openai
import json

# å®šä¹‰å¯ç”¨çš„å·¥å…·
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "åŸå¸‚åç§°"},
                    "date": {"type": "string", "description": "æ—¥æœŸï¼Œé»˜è®¤ä»Šå¤©"},
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "æ¸©åº¦å•ä½"
                    }
                },
                "required": ["city"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_weather_forecast",
            "description": "è·å–æœªæ¥å¤šå¤©çš„å¤©æ°”é¢„æŠ¥",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string"},
                    "days": {"type": "integer", "description": "é¢„æŠ¥å¤©æ•°"}
                },
                "required": ["city", "days"]
            }
        }
    }
]

# å®é™…çš„å·¥å…·å‡½æ•°
def get_weather(city, date="ä»Šå¤©", unit="celsius"):
    # å®é™…è°ƒç”¨å¤©æ°” API
    return f"{city}{date}çš„å¤©æ°”ï¼šæ™´ï¼Œ25Â°C"

def get_weather_forecast(city, days):
    return f"{city}æœªæ¥{days}å¤©å¤©æ°”é¢„æŠ¥ï¼š..."

# Agent ä¸»å¾ªç¯
def run_agent(user_message):
    messages = [{"role": "user", "content": user_message}]
    
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šLLM å†³å®šè°ƒç”¨ä»€ä¹ˆå‡½æ•°
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages,
        tools=tools,
        tool_choice="auto"
    )
    
    response_message = response.choices[0].message
    
    # å¦‚æœ LLM å†³å®šè°ƒç”¨å‡½æ•°
    if response_message.tool_calls:
        # æ‰§è¡Œå‡½æ•°è°ƒç”¨
        for tool_call in response_message.tool_calls:
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments)
            
            # è°ƒç”¨å®é™…å‡½æ•°
            if function_name == "get_weather":
                function_response = get_weather(**function_args)
            elif function_name == "get_weather_forecast":
                function_response = get_weather_forecast(**function_args)
            
            # å°†å‡½æ•°ç»“æœæ·»åŠ åˆ°å¯¹è¯
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": function_response
            })
        
        # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šè®© LLM åŸºäºå‡½æ•°ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤
        final_response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=messages
        )
        
        return final_response.choices[0].message.content
    
    # å¦‚æœä¸éœ€è¦è°ƒç”¨å‡½æ•°ï¼Œç›´æ¥è¿”å›
    return response_message.content

# æµ‹è¯•
print(run_agent("æ˜å¤©åŒ—äº¬ä¼šä¸‹é›¨å—ï¼Ÿ"))
# LLM è‡ªåŠ¨ï¼š1. è¯†åˆ«éœ€è¦è°ƒç”¨ get_weather
#          2. æå–å‚æ•° city="åŒ—äº¬", date="æ˜å¤©"
#          3. æ‰§è¡Œå‡½æ•°
#          4. ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤ï¼š"æ ¹æ®æŸ¥è¯¢ï¼Œæ˜å¤©åŒ—äº¬æ˜¯æ™´å¤©ï¼Œä¸ä¼šä¸‹é›¨ã€‚"
```

### Function Calling çš„åº”ç”¨åœºæ™¯

1. **æ™ºèƒ½åŠ©æ‰‹**
   - æ—¥ç¨‹ç®¡ç†ã€é‚®ä»¶å‘é€ã€æé†’è®¾ç½®
   - è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·å®Œæˆä»»åŠ¡

2. **æ•°æ®æŸ¥è¯¢**
   - æ•°æ®åº“æŸ¥è¯¢ã€API è°ƒç”¨ã€æ–‡ä»¶æ“ä½œ
   - è‡ªåŠ¨æ„å»ºæŸ¥è¯¢è¯­å¥

3. **å·¥ä½œæµè‡ªåŠ¨åŒ–**
   - å¤šæ­¥éª¤ä»»åŠ¡ç¼–æ’
   - è‡ªåŠ¨å¤„ç†ä»»åŠ¡ä¾èµ–

4. **ä¼ä¸šåº”ç”¨**
   - CRM ç³»ç»Ÿæ“ä½œã€æŠ¥è¡¨ç”Ÿæˆã€å®¡æ‰¹æµç¨‹
   - ç»Ÿä¸€çš„è‡ªç„¶è¯­è¨€æ¥å£

### æ€»ç»“

**Function Calling æ¯”ä¼ ç»Ÿ Slot Filling æ›´å…ˆè¿›çš„æ ¸å¿ƒåŸå› **ï¼š

1. **ç«¯åˆ°ç«¯**ï¼šä»è‡ªç„¶è¯­è¨€åˆ°å‡½æ•°è°ƒç”¨ä¸€æ°”å‘µæˆï¼Œæ— éœ€å¤šæ­¥å¤„ç†
2. **æ™ºèƒ½åŒ–**ï¼šLLM è‡ªåŠ¨å®Œæˆæ„å›¾è¯†åˆ«ã€å‚æ•°æå–ã€ç±»å‹è½¬æ¢ã€å‚æ•°éªŒè¯
3. **æ ‡å‡†åŒ–**ï¼šåŸºäº JSON Schema çš„æ ‡å‡†å®šä¹‰ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
4. **é«˜æ•ˆç‡**ï¼šå‡å°‘å¼€å‘æˆæœ¬ï¼Œæé«˜å‡†ç¡®æ€§ï¼Œé™ä½ç»´æŠ¤è´Ÿæ‹…

Function Calling æ˜¯ AI Agent æŠ€æœ¯çš„é‡è¦é‡Œç¨‹ç¢‘ï¼Œå®ƒå°†å¤æ‚çš„æ„å›¾è¯†åˆ«å’Œå‚æ•°æå–æµç¨‹ç®€åŒ–ä¸ºä¸€æ¬¡ LLM è°ƒç”¨ï¼Œå¤§å¹…æå‡äº†å¼€å‘æ•ˆç‡å’Œç³»ç»Ÿå¯é æ€§ã€‚

## å…¶ä»–æ„å›¾è¯†åˆ«ä¸å·¥å…·è°ƒç”¨æ–¹å¼

é™¤äº†ä¼ ç»Ÿçš„ Slot Filling å’Œç°ä»£çš„ Function Callingï¼ŒAI Agent è¿˜æœ‰å¤šç§å®ç°æ„å›¾è¯†åˆ«å’Œå·¥å…·è°ƒç”¨çš„æ–¹å¼ï¼Œå„æœ‰ç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚

### 1. ReActï¼ˆReasoning + Actingï¼‰

ReAct æ˜¯ä¸€ç§è®© LLM äº¤æ›¿è¿›è¡Œæ¨ç†ï¼ˆReasoningï¼‰å’Œè¡ŒåŠ¨ï¼ˆActingï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰å¼•å¯¼ LLM ä¸€æ­¥æ­¥åˆ†æé—®é¢˜å¹¶é€‰æ‹©å·¥å…·ã€‚

#### å·¥ä½œåŸç†

```
ç”¨æˆ·è¾“å…¥ â†’ LLM æ¨ç†(Thought) â†’ å†³å®šè¡ŒåŠ¨(Action) â†’ æ‰§è¡Œå·¥å…· â†’ è§‚å¯Ÿç»“æœ(Observation) â†’ ç»§ç»­æ¨ç† â†’ ...
```

#### å®ç°ç¤ºä¾‹

```python
react_prompt_template = """
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
1. search(query): æœç´¢ä¿¡æ¯
2. calculate(expression): è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
3. get_weather(city): æŸ¥è¯¢å¤©æ°”

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹]
Action: [å·¥å…·åç§°]
Action Input: [å·¥å…·å‚æ•°]
Observation: [å·¥å…·è¿”å›çš„ç»“æœ]
... (é‡å¤ Thought/Action/Observation ç›´åˆ°å¾—å‡ºç­”æ¡ˆ)
Answer: [æœ€ç»ˆç­”æ¡ˆ]

é—®é¢˜ï¼š{question}
"""

# ç”¨æˆ·é—®é¢˜ï¼š"åŒ—äº¬æ˜å¤©çš„å¤©æ°”é€‚åˆæˆ·å¤–æ´»åŠ¨å—ï¼Ÿ"

# LLM è¾“å‡ºï¼š
"""
Thought: æˆ‘éœ€è¦å…ˆæŸ¥è¯¢åŒ—äº¬æ˜å¤©çš„å¤©æ°”
Action: get_weather
Action Input: {"city": "åŒ—äº¬", "date": "æ˜å¤©"}
Observation: æ˜å¤©åŒ—äº¬å¤©æ°”ï¼šæ™´ï¼Œæ¸©åº¦ 22Â°Cï¼Œå¾®é£

Thought: æ ¹æ®å¤©æ°”ä¿¡æ¯ï¼Œæ™´å¤©ã€æ¸©åº¦é€‚ä¸­ã€å¾®é£ï¼Œéå¸¸é€‚åˆæˆ·å¤–æ´»åŠ¨
Answer: æ ¹æ®å¤©æ°”é¢„æŠ¥ï¼ŒåŒ—äº¬æ˜å¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦ 22Â°Cï¼Œå¾®é£ï¼Œéå¸¸é€‚åˆæˆ·å¤–æ´»åŠ¨ã€‚
"""
```

#### ä¼˜åŠ¿
- **å¯è§£é‡Šæ€§å¼º**ï¼šæ¯ä¸€æ­¥æ¨ç†è¿‡ç¨‹éƒ½æ¸…æ™°å¯è§
- **çµæ´»æ€§é«˜**ï¼šLLM å¯ä»¥åŠ¨æ€è°ƒæ•´ç­–ç•¥
- **æ”¯æŒå¤æ‚ä»»åŠ¡**ï¼šå¯ä»¥è¿›è¡Œå¤šæ­¥æ¨ç†å’Œå·¥å…·è°ƒç”¨

#### åŠ£åŠ¿
- **Token æ¶ˆè€—å¤§**ï¼šæ¯æ¬¡æ¨ç†éƒ½éœ€è¦å®Œæ•´çš„å¯¹è¯å†å²
- **é€Ÿåº¦è¾ƒæ…¢**ï¼šéœ€è¦å¤šæ¬¡ LLM è°ƒç”¨
- **æ ¼å¼ä¾èµ–**ï¼šä¾èµ– LLM ä¸¥æ ¼éµå¾ªè¾“å‡ºæ ¼å¼

### 2. Prompt-based Tool Selectionï¼ˆåŸºäºæç¤ºçš„å·¥å…·é€‰æ‹©ï¼‰

é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ Prompt è®© LLM ç›´æ¥è¾“å‡ºå·¥å…·è°ƒç”¨çš„ JSON æˆ–ç»“æ„åŒ–æ–‡æœ¬ã€‚

#### å®ç°ç¤ºä¾‹

```python
tool_selection_prompt = """
æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å¹¶æå–å‚æ•°ã€‚

å¯ç”¨å·¥å…·ï¼š
- get_weather: æŸ¥è¯¢å¤©æ°”ï¼Œå‚æ•°: city, date
- send_email: å‘é€é‚®ä»¶ï¼Œå‚æ•°: to, subject, body
- search: æœç´¢ä¿¡æ¯ï¼Œå‚æ•°: query

ç”¨æˆ·è¾“å…¥ï¼š{user_input}

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{
  "tool": "å·¥å…·åç§°",
  "parameters": {
    "å‚æ•°å": "å‚æ•°å€¼"
  }
}
"""

# ç”¨æˆ·ï¼š"æŸ¥è¯¢æ˜å¤©ä¸Šæµ·çš„å¤©æ°”"
# LLM è¿”å›ï¼š
{
  "tool": "get_weather",
  "parameters": {
    "city": "ä¸Šæµ·",
    "date": "æ˜å¤©"
  }
}
```

#### ä¼˜åŠ¿
- **ç®€å•ç›´æ¥**ï¼šä¸éœ€è¦ç‰¹æ®Š API æ”¯æŒ
- **é€‚é…æ€§å¥½**ï¼šé€‚ç”¨äºä»»ä½• LLM
- **æˆæœ¬ä½**ï¼šä¸€æ¬¡è°ƒç”¨å®Œæˆ

#### åŠ£åŠ¿
- **é²æ£’æ€§å·®**ï¼šLLM å¯èƒ½ä¸ä¸¥æ ¼éµå¾ª JSON æ ¼å¼
- **éœ€è¦åå¤„ç†**ï¼šéœ€è¦è§£æå’ŒéªŒè¯è¾“å‡º
- **é”™è¯¯å¤„ç†å¤æ‚**ï¼šæ ¼å¼é”™è¯¯éœ€è¦é‡è¯•

### 3. Semantic Kernel / LangChain é£æ ¼çš„ Plugin ç³»ç»Ÿ

ä½¿ç”¨æ¡†æ¶æä¾›çš„æ’ä»¶æœºåˆ¶ï¼Œé€šè¿‡è£…é¥°å™¨æˆ–é…ç½®æ–‡ä»¶å®šä¹‰å·¥å…·ã€‚

#### LangChain ç¤ºä¾‹

```python
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.tools import BaseTool

# å®šä¹‰å·¥å…·
class WeatherTool(BaseTool):
    name = "get_weather"
    description = "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯ã€‚è¾“å…¥ï¼šåŸå¸‚åç§°"
    
    def _run(self, city: str) -> str:
        return f"{city}çš„å¤©æ°”ï¼šæ™´æœ—"

class EmailTool(BaseTool):
    name = "send_email"
    description = "å‘é€é‚®ä»¶ã€‚è¾“å…¥ï¼šæ”¶ä»¶äºº,ä¸»é¢˜,æ­£æ–‡"
    
    def _run(self, to: str, subject: str, body: str) -> str:
        return f"å·²å‘é€é‚®ä»¶ç»™ {to}"

# åˆ›å»º Agent
tools = [WeatherTool(), EmailTool()]
agent = create_react_agent(llm, tools, prompt_template)
agent_executor = AgentExecutor(agent=agent, tools=tools)

# æ‰§è¡Œ
result = agent_executor.run("æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”å¹¶å‘é‚®ä»¶é€šçŸ¥å¼ ä¸‰")
```

#### ä¼˜åŠ¿
- **ç”Ÿæ€ä¸°å¯Œ**ï¼šå¤§é‡ç°æˆçš„å·¥å…·å’Œæ’ä»¶
- **æ˜“äºæ‰©å±•**ï¼šæ·»åŠ æ–°å·¥å…·åªéœ€å®šä¹‰ç±»
- **é›†æˆç®€å•**ï¼šæ¡†æ¶å¤„ç†å¤§éƒ¨åˆ†å¤æ‚é€»è¾‘

#### åŠ£åŠ¿
- **æ¡†æ¶ä¾èµ–**ï¼šç»‘å®šç‰¹å®šæ¡†æ¶
- **å­¦ä¹ æˆæœ¬**ï¼šéœ€è¦ç†è§£æ¡†æ¶æ¦‚å¿µ
- **è°ƒè¯•å›°éš¾**ï¼šæ¡†æ¶æŠ½è±¡å±‚å¢åŠ å¤æ‚åº¦

### 4. Tool Retrievalï¼ˆå·¥å…·æ£€ç´¢ï¼‰

å½“å¯ç”¨å·¥å…·æ•°é‡å¾ˆå¤šæ—¶ï¼Œå…ˆé€šè¿‡å‘é‡æ£€ç´¢ç­›é€‰ç›¸å…³å·¥å…·ï¼Œå†è®© LLM é€‰æ‹©ã€‚

#### å®ç°ç¤ºä¾‹

```python
from sentence_transformers import SentenceTransformer
import numpy as np

# 1. å·¥å…·åº“ï¼ˆåŒ…å«æè¿°ï¼‰
tools_library = [
    {"name": "get_weather", "description": "æŸ¥è¯¢åŸå¸‚å¤©æ°”ä¿¡æ¯"},
    {"name": "send_email", "description": "å‘é€ç”µå­é‚®ä»¶"},
    {"name": "search_web", "description": "åœ¨ç½‘ç»œä¸Šæœç´¢ä¿¡æ¯"},
    {"name": "calculate", "description": "è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"},
    # ... 100+ ä¸ªå·¥å…·
]

# 2. å‘é‡åŒ–å·¥å…·æè¿°
model = SentenceTransformer('all-MiniLM-L6-v2')
tool_embeddings = model.encode([t["description"] for t in tools_library])

# 3. æ£€ç´¢ç›¸å…³å·¥å…·
def retrieve_tools(user_query, top_k=3):
    query_embedding = model.encode([user_query])
    similarities = np.dot(query_embedding, tool_embeddings.T)[0]
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    return [tools_library[i] for i in top_indices]

# 4. è®© LLM ä»å€™é€‰å·¥å…·ä¸­é€‰æ‹©
user_query = "æ˜å¤©åŒ—äº¬ä¼šä¸‹é›¨å—ï¼Ÿ"
candidate_tools = retrieve_tools(user_query)  # è¿”å›ï¼šget_weather, search_web

# 5. LLM ä»å€™é€‰ä¸­é€‰æ‹©
function_calling_with_candidates(user_query, candidate_tools)
```

#### ä¼˜åŠ¿
- **å¯æ‰©å±•**ï¼šæ”¯æŒå¤§è§„æ¨¡å·¥å…·åº“
- **é«˜æ•ˆ**ï¼šå‡å°‘ LLM éœ€è¦å¤„ç†çš„å·¥å…·æ•°é‡
- **å‡†ç¡®æ€§é«˜**ï¼šé¿å…å·¥å…·é€‰æ‹©æ··æ·†

#### åŠ£åŠ¿
- **é¢å¤–å¼€é”€**ï¼šéœ€è¦å‘é‡åŒ–å’Œæ£€ç´¢æ­¥éª¤
- **ä¾èµ–è´¨é‡**ï¼šå·¥å…·æè¿°è´¨é‡å½±å“æ£€ç´¢æ•ˆæœ
- **å¤æ‚åº¦å¢åŠ **ï¼šç³»ç»Ÿæ¶æ„æ›´å¤æ‚

### 5. Code Generationï¼ˆä»£ç ç”Ÿæˆï¼‰

è®© LLM ç›´æ¥ç”Ÿæˆå¯æ‰§è¡Œä»£ç æ¥è°ƒç”¨å·¥å…·ã€‚

#### å®ç°ç¤ºä¾‹

```python
code_gen_prompt = """
ä½ æœ‰ä»¥ä¸‹ Python å‡½æ•°å¯ç”¨ï¼š
- get_weather(city, date)
- send_email(to, subject, body)
- calculate(expression)

æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆ Python ä»£ç æ¥å®Œæˆä»»åŠ¡ã€‚

ç”¨æˆ·ï¼šæŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”
ä»£ç ï¼š
```python
result = get_weather("åŒ—äº¬", "æ˜å¤©")
print(result)
```

ç”¨æˆ·ï¼š{user_input}
ä»£ç ï¼š
"""

# LLM ç”Ÿæˆï¼š
"""
```python
weather = get_weather("ä¸Šæµ·", "æ˜å¤©")
send_email("user@example.com", "å¤©æ°”é€šçŸ¥", f"æ˜å¤©ä¸Šæµ·å¤©æ°”ï¼š{weather}")
```
"""

# æ‰§è¡Œç”Ÿæˆçš„ä»£ç 
exec(generated_code)
```

#### ä¼˜åŠ¿
- **çµæ´»æ€§æé«˜**ï¼šå¯ä»¥å®ç°å¤æ‚çš„é€»è¾‘ç»„åˆ
- **æ— éœ€é¢„å®šä¹‰**ï¼šä¸éœ€è¦ä¸¥æ ¼çš„å·¥å…· schema
- **æ”¯æŒç»„åˆ**ï¼šå¯ä»¥ç»„åˆå¤šä¸ªå·¥å…·è°ƒç”¨

#### åŠ£åŠ¿
- **å®‰å…¨é£é™©**ï¼šæ‰§è¡Œç”Ÿæˆçš„ä»£ç æœ‰å®‰å…¨éšæ‚£
- **éš¾ä»¥æ§åˆ¶**ï¼šç”Ÿæˆçš„ä»£ç å¯èƒ½ä¸ç¬¦åˆé¢„æœŸ
- **è°ƒè¯•å›°éš¾**ï¼šä»£ç é”™è¯¯éš¾ä»¥è¿½è¸ª

### 6. Fine-tuned Modelï¼ˆå¾®è°ƒæ¨¡å‹ï¼‰

ä¸“é—¨è®­ç»ƒä¸€ä¸ªå°æ¨¡å‹ç”¨äºæ„å›¾è¯†åˆ«å’Œå‚æ•°æå–ã€‚

#### å®ç°æµç¨‹

```python
# 1. å‡†å¤‡è®­ç»ƒæ•°æ®
training_data = [
    {
        "input": "æŸ¥è¯¢æ˜å¤©åŒ—äº¬çš„å¤©æ°”",
        "output": {
            "intent": "get_weather",
            "params": {"city": "åŒ—äº¬", "date": "æ˜å¤©"}
        }
    },
    # ... æ•°åƒæ¡æ ‡æ³¨æ•°æ®
]

# 2. å¾®è°ƒæ¨¡å‹
from transformers import AutoModelForSequenceClassification, Trainer

model = AutoModelForSequenceClassification.from_pretrained("bert-base-chinese")
trainer = Trainer(model=model, train_dataset=training_data)
trainer.train()

# 3. æ¨ç†
def predict_intent_and_params(text):
    result = model(text)
    return result  # {"intent": "...", "params": {...}}
```

#### ä¼˜åŠ¿
- **é€Ÿåº¦å¿«**ï¼šæ¨ç†é€Ÿåº¦è¿œå¿«äºå¤§æ¨¡å‹
- **æˆæœ¬ä½**ï¼šè¿è¡Œæˆæœ¬ä½ï¼Œå¯æœ¬åœ°éƒ¨ç½²
- **ç¨³å®šæ€§é«˜**ï¼šè¾“å‡ºæ ¼å¼å¯æ§

#### åŠ£åŠ¿
- **éœ€è¦æ ‡æ³¨æ•°æ®**ï¼šéœ€è¦å¤§é‡äººå·¥æ ‡æ³¨
- **çµæ´»æ€§å·®**ï¼šéš¾ä»¥å¤„ç†è®­ç»ƒé›†å¤–çš„æƒ…å†µ
- **ç»´æŠ¤æˆæœ¬é«˜**ï¼šæ–°å¢å·¥å…·éœ€è¦é‡æ–°è®­ç»ƒ

### æ–¹æ³•å¯¹æ¯”æ€»ç»“

| æ–¹æ³• | å¤æ‚åº¦ | çµæ´»æ€§ | æˆæœ¬ | é€‚ç”¨åœºæ™¯ |
|-----|-------|-------|-----|---------|
| **Slot Filling** | ä¸­ | ä¸­ | ä¸­ | ä¼ ç»Ÿ NLU ç³»ç»Ÿ |
| **Function Calling** | ä½ | é«˜ | ä¸­ | ç°ä»£ AI Agentï¼ˆæ¨èï¼‰ |
| **ReAct** | é«˜ | æé«˜ | é«˜ | å¤æ‚æ¨ç†ä»»åŠ¡ |
| **Prompt-based** | ä½ | ä¸­ | ä½ | ç®€å•å¿«é€ŸåŸå‹ |
| **LangChain/Semantic Kernel** | ä¸­ | é«˜ | ä¸­ | å¿«é€Ÿå¼€å‘ï¼Œç”Ÿæ€éœ€æ±‚ |
| **Tool Retrieval** | é«˜ | é«˜ | ä¸­ | å¤§è§„æ¨¡å·¥å…·åº“ |
| **Code Generation** | é«˜ | æé«˜ | é«˜ | é«˜åº¦çµæ´»éœ€æ±‚ |
| **Fine-tuned Model** | ä¸­ | ä½ | ä½ï¼ˆæ¨ç†ï¼‰ | é«˜æ€§èƒ½ã€ä½å»¶è¿Ÿéœ€æ±‚ |

### å®é™…é¡¹ç›®ä¸­çš„é€‰æ‹©å»ºè®®

1. **ç®€å•åœºæ™¯ï¼ˆ<5 ä¸ªå·¥å…·ï¼‰**
   - é¦–é€‰ï¼š**Function Calling**
   - å¤‡é€‰ï¼šPrompt-based

2. **ä¸­ç­‰å¤æ‚åº¦ï¼ˆ5-20 ä¸ªå·¥å…·ï¼‰**
   - é¦–é€‰ï¼š**Function Calling** + LangChain
   - å¤‡é€‰ï¼šReAct

3. **å¤§è§„æ¨¡å·¥å…·åº“ï¼ˆ>20 ä¸ªå·¥å…·ï¼‰**
   - é¦–é€‰ï¼š**Tool Retrieval** + Function Calling
   - å¤‡é€‰ï¼šLangChain Agents

4. **éœ€è¦å¤æ‚æ¨ç†**
   - é¦–é€‰ï¼š**ReAct**
   - å¤‡é€‰ï¼šCode Generation

5. **æ€§èƒ½æ•æ„Ÿåœºæ™¯**
   - é¦–é€‰ï¼š**Fine-tuned Model**
   - å¤‡é€‰ï¼šç®€åŒ–ç‰ˆ Function Calling

6. **å¿«é€ŸåŸå‹**
   - é¦–é€‰ï¼š**Prompt-based**
   - å¤‡é€‰ï¼šLangChain

### æ··åˆæ–¹æ¡ˆ

å®é™…é¡¹ç›®ä¸­å¸¸å¸¸ç»“åˆå¤šç§æ–¹æ³•ï¼š

```python
# ç¤ºä¾‹ï¼šTool Retrieval + Function Calling
def hybrid_agent(user_input):
    # 1. å·¥å…·æ£€ç´¢ï¼šä» 100+ å·¥å…·ä¸­ç­›é€‰å‡º 5 ä¸ªå€™é€‰
    candidate_tools = retrieve_tools(user_input, top_k=5)
    
    # 2. Function Callingï¼šä»å€™é€‰ä¸­ç²¾ç¡®é€‰æ‹©
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": user_input}],
        tools=candidate_tools,  # åªä¼ å…¥å€™é€‰å·¥å…·
        tool_choice="auto"
    )
    
    return response
```

**æ€»ç»“**ï¼šFunction Calling æ˜¯å½“å‰æœ€æ¨èçš„æ–¹æ³•ï¼Œä½†æ ¹æ®å…·ä½“éœ€æ±‚ï¼ˆå·¥å…·æ•°é‡ã€æ€§èƒ½è¦æ±‚ã€å¤æ‚åº¦ç­‰ï¼‰ï¼Œå¯ä»¥é€‰æ‹©æˆ–ç»„åˆå…¶ä»–æ–¹æ³•æ¥ä¼˜åŒ–ç³»ç»Ÿã€‚

### è¡Œä¸šè¶‹åŠ¿ä¸æœ€ä½³å®è·µ

#### å½“å‰æœ€æµè¡Œçš„æ–¹å¼ï¼ˆ2024-2025ï¼‰

**æŒ‰æŠ€æœ¯å±‚æ¬¡åˆ†ç±»**ï¼š

**1. åº•å±‚æŠ€æœ¯ï¼šå·¥å…·è°ƒç”¨æœºåˆ¶**

**Function Callingï¼ˆåŸç”Ÿ APIï¼‰â€”â€” è¡Œä¸šæ ‡å‡†**

- **æä¾›è€…**ï¼šOpenAIã€Anthropic (Claude)ã€Google (Gemini)ã€ç™¾åº¦æ–‡å¿ƒã€é˜¿é‡Œé€šä¹‰
- **å¸‚åœºå æœ‰ç‡**ï¼šè¶…è¿‡ 80% çš„é¡¹ç›®ä½¿ç”¨ï¼ˆç›´æ¥æˆ–é€šè¿‡æ¡†æ¶ï¼‰
- **å…¸å‹åº”ç”¨**ï¼š
  - ChatGPT Plugins
  - GitHub Copilot Extensions
  - ä¼ä¸šçº§ AI åŠ©æ‰‹
  - æ‰€æœ‰ä¸»æµ Agent æ¡†æ¶çš„åº•å±‚å®ç°

**ä¸ºä»€ä¹ˆæ˜¯æ ‡å‡†ï¼Ÿ**
- âœ… LLM åŸç”Ÿæ”¯æŒï¼Œç¨³å®šå¯é 
- âœ… å¼€å‘æ•ˆç‡æœ€é«˜ï¼Œä»£ç é‡æœ€å°‘
- âœ… ä¸ LLM èƒ½åŠ›æ·±åº¦é›†æˆ
- âœ… æŒç»­è¿­ä»£ä¼˜åŒ–ï¼ˆå¦‚ Parallel Function Callingï¼‰

**2. ä¸Šå±‚æ¡†æ¶ï¼šå¼€å‘å·¥å…·**

**LangChain/LlamaIndex â€”â€” ä¸»æµå¼€å‘æ¡†æ¶**

- **æ€§è´¨**ï¼šå¼€æºæ¡†æ¶ï¼Œ**åº•å±‚ä½¿ç”¨ Function Calling**
- **é‡‡ç”¨è€…**ï¼šåˆåˆ›å…¬å¸ã€å¿«é€ŸåŸå‹ã€ç ”ç©¶é¡¹ç›®ã€ä¼ä¸šåº”ç”¨
- **å¸‚åœºå æœ‰ç‡**ï¼šçº¦ 40% çš„é¡¹ç›®ä½¿ç”¨æ¡†æ¶ï¼ˆè€Œéç›´æ¥è°ƒç”¨ APIï¼‰
- **ä¼˜åŠ¿**ï¼š
  - ä¸°å¯Œçš„é¢„æ„å»ºç»„ä»¶å’Œé›†æˆ
  - æ´»è·ƒçš„ç¤¾åŒºå’Œç”Ÿæ€
  - å¿«é€Ÿè¿­ä»£å’Œéƒ¨ç½²
  - å°è£…äº†å¤æ‚çš„æµç¨‹ï¼ˆRAGã€Multi-Agentï¼‰

**é€‚ç”¨åœºæ™¯**ï¼š
- RAG åº”ç”¨ï¼ˆæ–‡æ¡£é—®ç­”ï¼‰
- å¤æ‚çš„å¤šæ­¥éª¤ Agent æµç¨‹
- éœ€è¦é›†æˆå¤šç§æ•°æ®æº
- å¿«é€ŸéªŒè¯æƒ³æ³•

**è¯´æ˜**ï¼šLangChain å¹¶éç‹¬ç«‹çš„å·¥å…·è°ƒç”¨æŠ€æœ¯ï¼Œè€Œæ˜¯**æ„å»ºåœ¨ Function Calling ä¹‹ä¸Šçš„å¼€å‘æ¡†æ¶**ã€‚å®ƒé€šè¿‡å°è£…å’ŒæŠ½è±¡ï¼Œè®©å¼€å‘è€…æ— éœ€ç›´æ¥å¤„ç† Function Calling çš„ç»†èŠ‚ã€‚

**3. ç‰¹å®šæ¨¡å¼ï¼šæ¨ç†æ–¹å¼**

**ReAct â€”â€” æ¨ç†-è¡ŒåŠ¨æ¨¡å¼**

- **æ€§è´¨**ï¼šä¸€ç§ Agent å·¥ä½œæ¨¡å¼ï¼Œ**å¯ä»¥ç”¨ Function Calling æˆ– LangChain å®ç°**
- **é‡‡ç”¨è€…**ï¼šç ”ç©¶æœºæ„ã€éœ€è¦å¯è§£é‡Šæ€§çš„åœºæ™¯
- **å¸‚åœºå æœ‰ç‡**ï¼šçº¦ 15%
- **å…¸å‹è®ºæ–‡**ï¼šReAct (ICLR 2023)ã€Reflexionã€AutoGPT

**å…³ç³»è¯´æ˜**ï¼š
- **Function Calling** = åº•å±‚æŠ€æœ¯ï¼ˆLLM æä¾›çš„èƒ½åŠ›ï¼‰
- **LangChain** = ä¸Šå±‚æ¡†æ¶ï¼ˆä½¿ç”¨ Function Calling å®ç°ï¼‰
- **ReAct** = å·¥ä½œæ¨¡å¼ï¼ˆå¯ç”¨ Function Calling æˆ– LangChain å®ç°ï¼‰

**å±‚æ¬¡å…³ç³»å›¾**ï¼š
```
ç”¨æˆ·åº”ç”¨
   â†“
[LangChain/LlamaIndex æ¡†æ¶] â† å¯é€‰
   â†“
[Function Calling API] â† æ ¸å¿ƒ
   â†“
[LLM (GPT-4/Claude)]
```

#### æœªæ¥å‘å±•è¶‹åŠ¿ï¼ˆ2025-2026ï¼‰

**ğŸš€ è¶‹åŠ¿ 1ï¼šFunction Calling æŒç»­ä¸»å¯¼**

é¢„æµ‹ï¼š**Function Calling å°†æˆä¸ºäº‹å®æ ‡å‡†**

- **åŸå› **ï¼š
  - æ‰€æœ‰ä¸»æµ LLM æä¾›å•†éƒ½åœ¨å¢å¼ºæ­¤èƒ½åŠ›
  - æ ‡å‡†åŒ–ç¨‹åº¦è¶Šæ¥è¶Šé«˜
  - æ€§èƒ½æŒç»­ä¼˜åŒ–ï¼ˆé€Ÿåº¦ã€å‡†ç¡®æ€§ï¼‰

- **å‘å±•æ–¹å‘**ï¼š
  - **Structured Outputs**ï¼šä¿è¯è¾“å‡ºæ ¼å¼ 100% ç¬¦åˆ schema
  - **Tool Discovery**ï¼šåŠ¨æ€å‘ç°å’Œæ¨èå·¥å…·
  - **Multi-Agent Coordination**ï¼šé€šè¿‡ Function Calling å®ç° Agent é—´åä½œ

**ğŸš€ è¶‹åŠ¿ 2ï¼šTool Retrieval + Function Calling æ··åˆæ¶æ„**

é¢„æµ‹ï¼š**å¤§è§„æ¨¡å·¥å…·åœºæ™¯çš„æ ‡å‡†æ–¹æ¡ˆ**

```python
# æœªæ¥ä¸»æµæ¶æ„
def next_gen_agent(user_query, tool_library_size=1000+):
    # ç¬¬ä¸€å±‚ï¼šè¯­ä¹‰æ£€ç´¢ï¼ˆå¿«é€Ÿç­›é€‰ï¼‰
    candidates = vector_search(user_query, top_k=5)
    
    # ç¬¬äºŒå±‚ï¼šFunction Callingï¼ˆç²¾ç¡®é€‰æ‹©ï¼‰
    tool_call = llm.function_call(user_query, tools=candidates)
    
    # ç¬¬ä¸‰å±‚ï¼šæ‰§è¡Œå’Œåé¦ˆ
    result = execute_tool(tool_call)
    return result
```

**åº”ç”¨åœºæ™¯**ï¼š
- ä¼ä¸šçº§ Agentï¼ˆ100+ å†…éƒ¨å·¥å…·ï¼‰
- å¼€æ”¾å¹³å°ï¼ˆç¬¬ä¸‰æ–¹å·¥å…·å¸‚åœºï¼‰
- å‚ç›´é¢†åŸŸ Agentï¼ˆåŒ»ç–—ã€é‡‘èã€æ³•å¾‹ï¼‰

**ğŸš€ è¶‹åŠ¿ 3ï¼šMulti-Modal Function Calling**

é¢„æµ‹ï¼š**å¤šæ¨¡æ€è¾“å…¥çš„å·¥å…·è°ƒç”¨**

```python
# æœªæ¥ç¤ºä¾‹ï¼šå›¾åƒ + æ–‡æœ¬ â†’ å·¥å…·è°ƒç”¨
response = llm.function_call(
    messages=[
        {"role": "user", "content": [
            {"type": "text", "text": "è¿™å¼ å›¾ç‰‡ä¸­çš„äº§å“å¤šå°‘é’±ï¼Ÿ"},
            {"type": "image_url", "image_url": "..."}
        ]}
    ],
    tools=[
        {"name": "product_search", ...},
        {"name": "price_lookup", ...}
    ]
)
# LLM è¯†åˆ«å›¾ç‰‡å†…å®¹å¹¶è°ƒç”¨ä»·æ ¼æŸ¥è¯¢å·¥å…·
```

**ğŸš€ è¶‹åŠ¿ 4ï¼šAgent ç¼–æ’æ¡†æ¶æˆç†Ÿ**

é¢„æµ‹ï¼š**æ ‡å‡†åŒ–çš„ Agent ç¼–æ’åè®®**

- **LangGraph**ï¼šDAG é£æ ¼çš„ Agent ç¼–æ’
- **AutoGen**ï¼šMulti-Agent å¯¹è¯æ¡†æ¶
- **CrewAI**ï¼šè§’è‰²åŒ–çš„ Agent å›¢é˜Ÿ

**å…¸å‹æ¶æ„**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ â†’ åè°ƒ Agent â†’ æ‹†è§£ä»»åŠ¡ â†’ å¹¶è¡Œè°ƒåº¦ä¸“ä¸š Agent â†’ ç»“æœæ±‡æ€»
           (Function Calling)  â†“         â†“
                          [æ•°æ®åˆ†æ Agent]  [æŠ¥å‘Šç”Ÿæˆ Agent]
                          [ä¿¡æ¯æ£€ç´¢ Agent]  [ä»£ç æ‰§è¡Œ Agent]
```

**ğŸš€ è¶‹åŠ¿ 5ï¼šæœ¬åœ°å°æ¨¡å‹ + Function Calling**

é¢„æµ‹ï¼š**è¾¹ç¼˜è®¡ç®—å’Œéšç§åœºæ™¯çš„è§£å†³æ–¹æ¡ˆ**

- **Llama 3.x**ã€**Mistral**ã€**Qwen** ç­‰å¼€æºæ¨¡å‹å¢å¼º Function Calling èƒ½åŠ›
- **Fine-tuned å°æ¨¡å‹**ï¼šé’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„å·¥å…·è°ƒç”¨
- **æ··åˆæ¶æ„**ï¼šæœ¬åœ°æ¨¡å‹åšå·¥å…·é€‰æ‹©ï¼Œäº‘ç«¯æ¨¡å‹åšå¤æ‚æ¨ç†

#### æŠ€æœ¯é€‰å‹å»ºè®®ï¼ˆ2025ï¼‰

**åœºæ™¯ 1ï¼šå•†ä¸šäº§å“ï¼ˆæ¨èæŒ‡æ•°ï¼šâ­â­â­â­â­ï¼‰**
```
æ–¹æ¡ˆï¼šFunction Calling (OpenAI/Claude/Gemini)
åŸå› ï¼šç¨³å®šã€å¯é ã€å¼€å‘æ•ˆç‡é«˜ã€æŒç»­ä¼˜åŒ–
æˆæœ¬ï¼šä¸­ç­‰ï¼ˆAPI è°ƒç”¨è´¹ç”¨ï¼‰
```

**åœºæ™¯ 2ï¼šä¼ä¸šå†…éƒ¨ç³»ç»Ÿï¼ˆæ¨èæŒ‡æ•°ï¼šâ­â­â­â­â­ï¼‰**
```
æ–¹æ¡ˆï¼šTool Retrieval + Function Calling
åŸå› ï¼šæ”¯æŒå¤§é‡å†…éƒ¨å·¥å…·ï¼Œå¯æ‰©å±•æ€§å¥½
æˆæœ¬ï¼šä¸­ç­‰
```

**åœºæ™¯ 3ï¼šç ”ç©¶å’ŒåŸå‹ï¼ˆæ¨èæŒ‡æ•°ï¼šâ­â­â­â­ï¼‰**
```
æ–¹æ¡ˆï¼šLangChain + Function Calling
åŸå› ï¼šå¿«é€Ÿå¼€å‘ï¼Œä¸°å¯Œçš„ç»„ä»¶
æˆæœ¬ï¼šä½ï¼ˆå¿«é€Ÿè¿­ä»£ï¼‰
```

**åœºæ™¯ 4ï¼šé«˜æ€§èƒ½/ç¦»çº¿åœºæ™¯ï¼ˆæ¨èæŒ‡æ•°ï¼šâ­â­â­ï¼‰**
```
æ–¹æ¡ˆï¼šFine-tuned Model æˆ– æœ¬åœ° Llama + Function Calling
åŸå› ï¼šä½å»¶è¿Ÿï¼Œæ— éœ€ç½‘ç»œï¼Œæˆæœ¬å¯æ§
æˆæœ¬ï¼šé«˜ï¼ˆè®­ç»ƒå’Œéƒ¨ç½²ï¼‰
```

**åœºæ™¯ 5ï¼šå¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆæ¨èæŒ‡æ•°ï¼šâ­â­â­â­ï¼‰**
```
æ–¹æ¡ˆï¼šReAct + Function Calling
åŸå› ï¼šå¯è§£é‡Šæ€§å¼ºï¼Œé€‚åˆå¤šæ­¥æ¨ç†
æˆæœ¬ï¼šé«˜ï¼ˆå¤šæ¬¡ LLM è°ƒç”¨ï¼‰
```

#### æŠ€æœ¯æŠ•èµ„å»ºè®®

**çŸ­æœŸï¼ˆ2025ï¼‰- å¿…é¡»æŒæ¡**
1. âœ… **Function Calling**ï¼ˆOpenAI/Claude APIï¼‰
2. âœ… **åŸºç¡€ Prompt Engineering**
3. âœ… **LangChain åŸºç¡€ä½¿ç”¨**

**ä¸­æœŸï¼ˆ2025-2026ï¼‰- å»ºè®®å­¦ä¹ **
1. â­ **Tool Retrieval**ï¼ˆå‘é‡æ£€ç´¢ + Function Callingï¼‰
2. â­ **Multi-Agent ç¼–æ’**ï¼ˆLangGraph/AutoGenï¼‰
3. â­ **å¼€æºæ¨¡å‹ Function Calling**ï¼ˆLlama 3.xï¼‰

**é•¿æœŸï¼ˆ2026+ï¼‰- å‰ç»å¸ƒå±€**
1. ğŸš€ **Multi-Modal Function Calling**
2. ğŸš€ **Agent-to-Agent åè®®**ï¼ˆå¦‚ A2Aã€MCPï¼‰
3. ğŸš€ **è¾¹ç¼˜ AI Agent**ï¼ˆæœ¬åœ°æ¨¡å‹ + Function Callingï¼‰

#### è¡Œä¸šæ•°æ®ï¼ˆ2024 è°ƒæŸ¥ï¼‰

æ ¹æ® AI Agent å¼€å‘è€…è°ƒæŸ¥æŠ¥å‘Šï¼š

| æŠ€æœ¯æ–¹æ¡ˆ | ä½¿ç”¨ç‡ | æ»¡æ„åº¦ | æœªæ¥è®¡åˆ’é‡‡ç”¨ç‡ |
|---------|--------|--------|---------------|
| Function Calling | 62% | 4.5/5 | 78% |
| LangChain | 28% | 3.8/5 | 35% |
| ReAct | 12% | 4.2/5 | 18% |
| Custom Prompt | 45% | 3.2/5 | 25% |
| Fine-tuned Model | 8% | 4.0/5 | 15% |

**å…³é”®æ´å¯Ÿ**ï¼š
- Function Calling ä½¿ç”¨ç‡å’Œæ»¡æ„åº¦æœ€é«˜
- 78% çš„å¼€å‘è€…è®¡åˆ’åœ¨æ–°é¡¹ç›®ä¸­ä½¿ç”¨ Function Calling
- LangChain ä½¿ç”¨ç‡é«˜ï¼Œä½†æ»¡æ„åº¦ç›¸å¯¹è¾ƒä½ï¼ˆæ¡†æ¶å¤æ‚åº¦ï¼‰
- Fine-tuned Model æ»¡æ„åº¦é«˜ï¼Œä½†é‡‡ç”¨ç‡ä½ï¼ˆé—¨æ§›é«˜ï¼‰

#### ç»“è®º

**å½“å‰æœ€ä½³å®è·µï¼ˆ2025ï¼‰**ï¼š
1. **åº•å±‚æŠ€æœ¯ï¼šFunction Calling** - æ‰€æœ‰æ–¹æ¡ˆçš„åŸºç¡€
2. **å¿«é€Ÿå¼€å‘ï¼šLangChainï¼ˆåŸºäº Function Callingï¼‰** - æ¡†æ¶ä¼˜åŠ¿
3. **å¤§è§„æ¨¡åœºæ™¯ï¼šTool Retrieval + Function Calling** - å¯æ‰©å±•æ¶æ„
4. **å¤æ‚æ¨ç†ï¼šReAct æ¨¡å¼ï¼ˆé€šè¿‡ Function Calling å®ç°ï¼‰** - å¯è§£é‡Šæ€§

**æœªæ¥è¶‹åŠ¿ï¼ˆ2025-2026ï¼‰**ï¼š
- Function Calling å°†æŒç»­ä¸»å¯¼ï¼Œèƒ½åŠ›ä¸æ–­å¢å¼º
- Tool Retrieval æˆä¸ºå¤§è§„æ¨¡ Agent çš„æ ‡é…
- Multi-Agent ç¼–æ’æ¡†æ¶é€æ¸æˆç†Ÿ
- å¤šæ¨¡æ€å’Œæœ¬åœ°åŒ–æ˜¯é‡è¦å‘å±•æ–¹å‘

**å»ºè®®**ï¼š
- âœ… **åº•å±‚èƒ½åŠ›**ï¼šæŒæ¡ Function Callingï¼ˆæ‰€æœ‰æ–¹æ¡ˆçš„åŸºç¡€ï¼‰
- âœ… **æ¡†æ¶é€‰æ‹©**ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©ç›´æ¥è°ƒç”¨ API æˆ–ä½¿ç”¨ LangChain
- âœ… **å¤§è§„æ¨¡åœºæ™¯**ï¼šå…³æ³¨ Tool Retrieval æŠ€æœ¯
- âœ… **è·Ÿè¸ªå‘å±•**ï¼šå¼€æºæ¨¡å‹çš„ Function Calling èƒ½åŠ›è¿›æ­¥
- âœ… **ç¼–æ’æ¡†æ¶**ï¼šäº†è§£ LangGraphã€AutoGenï¼ˆåŸºäº Function Calling çš„æ›´é«˜å±‚æŠ½è±¡ï¼‰

**æŠ€æœ¯æ ˆå…³ç³»**ï¼š
- **Function Calling**ï¼šå¿…é¡»æŒæ¡ï¼ˆåº•å±‚æŠ€æœ¯ï¼‰
- **LangChain**ï¼šå¯é€‰å­¦ä¹ ï¼ˆæé«˜å¼€å‘æ•ˆç‡çš„æ¡†æ¶ï¼‰
- **LangGraph/AutoGen**ï¼šè¿›é˜¶å­¦ä¹ ï¼ˆMulti-Agent ç¼–æ’ï¼‰

ä¸‰è€…éƒ½æ˜¯**åŸºäº Function Calling** æ„å»ºçš„ä¸åŒæŠ½è±¡å±‚æ¬¡ã€‚

## LangChain è¯¦è§£

### ä»€ä¹ˆæ˜¯ LangChain

LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨çš„å¼€æºæ¡†æ¶ã€‚å®ƒæä¾›äº†ä¸€å¥—æ ‡å‡†åŒ–çš„ç»„ä»¶å’Œå·¥å…·ï¼Œç®€åŒ–äº† AI Agentã€èŠå¤©æœºå™¨äººã€é—®ç­”ç³»ç»Ÿç­‰åº”ç”¨çš„å¼€å‘è¿‡ç¨‹ã€‚

**æ ¸å¿ƒç†å¿µ**ï¼šé€šè¿‡"é“¾ï¼ˆChainï¼‰"å°†å¤šä¸ªç»„ä»¶è¿æ¥èµ·æ¥ï¼Œæ„å»ºå¤æ‚çš„ LLM åº”ç”¨ã€‚

**å®˜æ–¹ä»“åº“**ï¼š
- Pythonï¼š`langchain-ai/langchain`
- JavaScript/TypeScriptï¼š`langchain-ai/langchainjs`

### æ ¸å¿ƒç»„ä»¶

#### 1. **Modelsï¼ˆæ¨¡å‹ï¼‰**

æ”¯æŒå¤šç§ LLM æä¾›å•†ï¼š

```python
from langchain.llms import OpenAI, Anthropic, HuggingFaceHub
from langchain.chat_models import ChatOpenAI, ChatAnthropic

# OpenAI
llm = OpenAI(temperature=0.7)

# Claude
chat = ChatAnthropic(model="claude-3-sonnet-20240229")

# æœ¬åœ°æ¨¡å‹
from langchain.llms import Ollama
local_llm = Ollama(model="llama2")
```

#### 2. **Promptsï¼ˆæç¤ºæ¨¡æ¿ï¼‰**

ç®¡ç†å’Œå¤ç”¨æç¤ºè¯ï¼š

```python
from langchain.prompts import PromptTemplate, ChatPromptTemplate

# ç®€å•æ¨¡æ¿
prompt = PromptTemplate(
    input_variables=["product"],
    template="ç»™{product}å†™ä¸€ä¸ªå¹¿å‘Šè¯­"
)

# èŠå¤©æ¨¡æ¿
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ª{role}"),
    ("human", "{user_input}")
])

# ä½¿ç”¨
formatted = prompt.format(product="æ™ºèƒ½æ‰‹è¡¨")
result = llm(formatted)
```

#### 3. **Chainsï¼ˆé“¾ï¼‰**

å°†å¤šä¸ªç»„ä»¶ä¸²è”ï¼š

```python
from langchain.chains import LLMChain, SimpleSequentialChain

# å•ä¸ªé“¾
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(product="æ™ºèƒ½æ‰‹è¡¨")

# é¡ºåºé“¾
chain1 = LLMChain(llm=llm, prompt=prompt1)  # ç”Ÿæˆäº§å“æè¿°
chain2 = LLMChain(llm=llm, prompt=prompt2)  # ç”Ÿæˆå¹¿å‘Šè¯­

overall_chain = SimpleSequentialChain(
    chains=[chain1, chain2],
    verbose=True
)
result = overall_chain.run("æ™ºèƒ½æ‰‹è¡¨")
```

#### 4. **Agentsï¼ˆä»£ç†ï¼‰**

åŠ¨æ€å†³ç­–å’Œå·¥å…·è°ƒç”¨ï¼š

```python
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.tools import BaseTool

# å®šä¹‰å·¥å…·
class WeatherTool(BaseTool):
    name = "Weather"
    description = "æŸ¥è¯¢å¤©æ°”ä¿¡æ¯ã€‚è¾“å…¥ï¼šåŸå¸‚åç§°"
    
    def _run(self, city: str) -> str:
        return f"{city}çš„å¤©æ°”ï¼šæ™´æœ—ï¼Œ25Â°C"
    
    async def _arun(self, city: str) -> str:
        return self._run(city)

# åˆ›å»º Agent
tools = [WeatherTool()]
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# æ‰§è¡Œ
result = agent.run("åŒ—äº¬æ˜å¤©ä¼šä¸‹é›¨å—ï¼Ÿ")
```

#### 5. **Memoryï¼ˆè®°å¿†ï¼‰**

ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡ï¼š

```python
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory
from langchain.chains import ConversationChain

# å®Œæ•´å†å²è®°å¿†
memory = ConversationBufferMemory()

# æ‘˜è¦è®°å¿†ï¼ˆèŠ‚çœ Tokenï¼‰
summary_memory = ConversationSummaryMemory(llm=llm)

# å¯¹è¯é“¾
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# å¤šè½®å¯¹è¯
conversation.predict(input="æˆ‘å«å¼ ä¸‰")
conversation.predict(input="æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ")  # å›ç­”ï¼šå¼ ä¸‰
```

#### 6. **Document Loadersï¼ˆæ–‡æ¡£åŠ è½½å™¨ï¼‰**

åŠ è½½å„ç§æ ¼å¼çš„æ•°æ®ï¼š

```python
from langchain.document_loaders import (
    TextLoader, PDFLoader, CSVLoader,
    UnstructuredHTMLLoader, GitbookLoader
)

# PDF æ–‡æ¡£
loader = PDFLoader("document.pdf")
documents = loader.load()

# ç½‘é¡µ
from langchain.document_loaders import WebBaseLoader
loader = WebBaseLoader("https://example.com")
documents = loader.load()
```

#### 7. **Vector Storesï¼ˆå‘é‡å­˜å‚¨ï¼‰**

æ”¯æŒ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼š

```python
from langchain.vectorstores import Chroma, FAISS, Pinecone
from langchain.embeddings import OpenAIEmbeddings

# åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=documents,
    embedding=embeddings
)

# ç›¸ä¼¼åº¦æ£€ç´¢
results = vectorstore.similarity_search("æŸ¥è¯¢æ–‡æœ¬", k=3)

# RAG é“¾
from langchain.chains import RetrievalQA

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
)

answer = qa_chain.run("ç”¨æˆ·é—®é¢˜")
```

### LangChain çš„ Agent ç±»å‹

#### 1. **Zero-shot ReAct**

ä¸éœ€è¦ç¤ºä¾‹ï¼Œç›´æ¥æ ¹æ®å·¥å…·æè¿°å†³ç­–ï¼š

```python
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)
```

#### 2. **Conversational ReAct**

å¸¦è®°å¿†çš„å¯¹è¯å‹ Agentï¼š

```python
memory = ConversationBufferMemory(memory_key="chat_history")

agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)
```

#### 3. **OpenAI Functions**

ä½¿ç”¨ OpenAI Function Callingï¼š

```python
agent = initialize_agent(
    tools=tools,
    llm=ChatOpenAI(model="gpt-4"),
    agent=AgentType.OPENAI_FUNCTIONS,
    verbose=True
)
```

#### 4. **Structured Chat**

æ”¯æŒå¤šå‚æ•°è¾“å…¥çš„ Agentï¼š

```python
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)
```

### å®æˆ˜ç¤ºä¾‹ï¼šå®Œæ•´çš„ RAG é—®ç­”ç³»ç»Ÿ

```python
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# 1. åŠ è½½æ–‡æ¡£
loader = DirectoryLoader(
    "./docs",
    glob="**/*.txt",
    loader_cls=TextLoader
)
documents = loader.load()

# 2. åˆ‡åˆ†æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
splits = text_splitter.split_documents(documents)

# 3. åˆ›å»ºå‘é‡å­˜å‚¨
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="./chroma_db"
)

# 4. å®šä¹‰æç¤ºæ¨¡æ¿
prompt_template = """
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä¸çŸ¥é“ï¼Œä¸è¦ç¼–é€ ç­”æ¡ˆã€‚

ä¸Šä¸‹æ–‡ï¼š{context}

é—®é¢˜ï¼š{question}

ç­”æ¡ˆï¼š
"""

PROMPT = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

# 5. åˆ›å»º QA é“¾
llm = ChatOpenAI(model="gpt-4", temperature=0)
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True,
    chain_type_kwargs={"prompt": PROMPT}
)

# 6. ä½¿ç”¨
query = "LangChain æ˜¯ä»€ä¹ˆï¼Ÿ"
result = qa_chain({"query": query})

print(result["result"])
print("\næ¥æºæ–‡æ¡£ï¼š")
for doc in result["source_documents"]:
    print(f"- {doc.metadata['source']}")
```

### LangChain Expression Language (LCEL)

æ–°ä¸€ä»£çš„é“¾å¼ç¼–ç¨‹æ–¹å¼ï¼ˆæ¨èï¼‰ï¼š

```python
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

# ä½¿ç”¨ LCEL æ„å»ºé“¾
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# æ‰§è¡Œ
result = chain.invoke("LangChain æ˜¯ä»€ä¹ˆï¼Ÿ")

# æµå¼è¾“å‡º
for chunk in chain.stream("LangChain æ˜¯ä»€ä¹ˆï¼Ÿ"):
    print(chunk, end="", flush=True)

# æ‰¹é‡å¤„ç†
results = chain.batch([
    "é—®é¢˜1",
    "é—®é¢˜2",
    "é—®é¢˜3"
])

# å¼‚æ­¥æ‰§è¡Œ
result = await chain.ainvoke("é—®é¢˜")
```

### LangGraph - é«˜çº§å·¥ä½œæµç¼–æ’

LangGraph æ˜¯ LangChain çš„æ‰©å±•ï¼Œç”¨äºæ„å»ºå¤æ‚çš„ Agent å·¥ä½œæµï¼š

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated

# å®šä¹‰çŠ¶æ€
class AgentState(TypedDict):
    messages: list
    next: str

# å®šä¹‰èŠ‚ç‚¹
def call_model(state):
    response = llm.invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

def should_continue(state):
    last_message = state["messages"][-1]
    if "FINAL ANSWER" in last_message.content:
        return "end"
    return "continue"

# æ„å»ºå›¾
workflow = StateGraph(AgentState)
workflow.add_node("agent", call_model)
workflow.add_node("tools", call_tools)

workflow.set_entry_point("agent")
workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "continue": "tools",
        "end": END
    }
)
workflow.add_edge("tools", "agent")

app = workflow.compile()

# æ‰§è¡Œ
result = app.invoke({"messages": [HumanMessage(content="æŸ¥è¯¢å¤©æ°”")]})
```

### LangChain çš„ä¼˜åŠ¿ä¸åŠ£åŠ¿

#### ä¼˜åŠ¿

1. **ç”Ÿæ€ä¸°å¯Œ**
   - 100+ é›†æˆï¼ˆLLMã€å‘é‡æ•°æ®åº“ã€å·¥å…·ï¼‰
   - æ´»è·ƒçš„ç¤¾åŒºå’Œæ–‡æ¡£

2. **å¿«é€Ÿå¼€å‘**
   - é¢„æ„å»ºçš„ç»„ä»¶å’Œæ¨¡æ¿
   - å‡å°‘æ ·æ¿ä»£ç 

3. **çµæ´»æ€§**
   - æ”¯æŒå¤šç§ LLM æä¾›å•†
   - å¯è‡ªå®šä¹‰ç»„ä»¶

4. **RAG æ”¯æŒå®Œå–„**
   - æ–‡æ¡£åŠ è½½ã€åˆ‡åˆ†ã€å‘é‡åŒ–ä¸€ä½“åŒ–
   - å¤šç§æ£€ç´¢ç­–ç•¥

5. **æŒç»­æ›´æ–°**
   - LCELã€LangGraph ç­‰æ–°ç‰¹æ€§
   - è·Ÿè¿› LLM æœ€æ–°èƒ½åŠ›

#### åŠ£åŠ¿

1. **å­¦ä¹ æ›²çº¿é™¡å³­**
   - æ¦‚å¿µè¾ƒå¤šï¼ˆChainã€Agentã€Memory ç­‰ï¼‰
   - API é¢‘ç¹å˜åŠ¨

2. **æŠ½è±¡å±‚å¤æ‚**
   - è°ƒè¯•å›°éš¾
   - æ€§èƒ½å¼€é”€

3. **ç‰ˆæœ¬å…¼å®¹æ€§**
   - å¤§ç‰ˆæœ¬å‡çº§å¯èƒ½ç ´åå…¼å®¹æ€§
   - éœ€è¦é¢‘ç¹æ›´æ–°ä»£ç 

4. **è¿‡åº¦å·¥ç¨‹**
   - ç®€å•ä»»åŠ¡å¯èƒ½ä¸éœ€è¦æ¡†æ¶
   - Function Calling åœºæ™¯å¯èƒ½æ›´ç®€æ´

### LangChain vs åŸç”Ÿ Function Calling

| ç»´åº¦ | LangChain | åŸç”Ÿ Function Calling |
|-----|-----------|---------------------|
| **å­¦ä¹ æˆæœ¬** | é«˜ | ä½ |
| **å¼€å‘é€Ÿåº¦** | å¿«ï¼ˆRAGã€å¤æ‚æµç¨‹ï¼‰ | å¿«ï¼ˆç®€å•å·¥å…·è°ƒç”¨ï¼‰ |
| **ä»£ç å¯è¯»æ€§** | ä¸­ï¼ˆæŠ½è±¡å±‚å¤šï¼‰ | é«˜ |
| **è°ƒè¯•éš¾åº¦** | é«˜ | ä½ |
| **çµæ´»æ€§** | æé«˜ | ä¸­ |
| **æ€§èƒ½** | ä¸­ï¼ˆé¢å¤–å¼€é”€ï¼‰ | é«˜ |
| **é€‚ç”¨åœºæ™¯** | RAGã€å¤šæ­¥éª¤ã€å¤æ‚ç¼–æ’ | å·¥å…·è°ƒç”¨ã€ç®€å• Agent |

### ä½¿ç”¨å»ºè®®

**é€‚åˆä½¿ç”¨ LangChain çš„åœºæ™¯**ï¼š

1. âœ… **RAG åº”ç”¨**ï¼ˆæ–‡æ¡£é—®ç­”ã€çŸ¥è¯†åº“ï¼‰
2. âœ… **å¤æ‚å¤šæ­¥éª¤æµç¨‹**ï¼ˆéœ€è¦ç¼–æ’å¤šä¸ªæ“ä½œï¼‰
3. âœ… **éœ€è¦å¿«é€ŸåŸå‹**ï¼ˆåˆ©ç”¨é¢„æ„å»ºç»„ä»¶ï¼‰
4. âœ… **å¤šæ•°æ®æºé›†æˆ**ï¼ˆæ–‡æ¡£ã€æ•°æ®åº“ã€APIï¼‰
5. âœ… **å®éªŒå’Œç ”ç©¶**ï¼ˆå¿«é€Ÿå°è¯•ä¸åŒæ¶æ„ï¼‰

**ä¸é€‚åˆä½¿ç”¨ LangChain çš„åœºæ™¯**ï¼š

1. âŒ **ç®€å•çš„å·¥å…·è°ƒç”¨**ï¼ˆç›´æ¥ç”¨ Function Callingï¼‰
2. âŒ **æ€§èƒ½æ•æ„Ÿåœºæ™¯**ï¼ˆå‡å°‘æŠ½è±¡å±‚å¼€é”€ï¼‰
3. âŒ **ç”Ÿäº§ç¯å¢ƒç¨³å®šæ€§è¦æ±‚é«˜**ï¼ˆç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼‰
4. âŒ **å›¢é˜Ÿå¯¹æ¡†æ¶ä¸ç†Ÿæ‚‰**ï¼ˆå­¦ä¹ æˆæœ¬é«˜ï¼‰

### å®é™…é¡¹ç›®æ¶æ„å»ºè®®

**æ··åˆæ¶æ„ï¼ˆæœ€ä½³å®è·µï¼‰**ï¼š

```python
# ä½¿ç”¨ LangChain åš RAG
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# RAG éƒ¨åˆ†ä½¿ç”¨ LangChain
vectorstore = Chroma.from_documents(documents, OpenAIEmbeddings())
retriever = vectorstore.as_retriever()

# å·¥å…·è°ƒç”¨ä½¿ç”¨åŸç”Ÿ Function Calling
tools_schema = [
    {
        "type": "function",
        "function": {
            "name": "search_knowledge_base",
            "description": "åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string"}
                }
            }
        }
    }
]

def search_knowledge_base(query: str):
    # ä½¿ç”¨ LangChain çš„æ£€ç´¢å™¨
    docs = retriever.get_relevant_documents(query)
    return "\n".join([doc.page_content for doc in docs])

# Agent ä¸»å¾ªç¯ä½¿ç”¨åŸç”Ÿ API
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=messages,
    tools=tools_schema
)

# ç»“åˆä¸¤è€…ä¼˜åŠ¿ï¼šLangChain å¤„ç†å¤æ‚æ•°æ®ï¼ŒFunction Calling åšå·¥å…·è°ƒç”¨
```

### æ€»ç»“

LangChain æ˜¯ä¸€ä¸ª**åŠŸèƒ½å¼ºå¤§ä½†å¤æ‚çš„æ¡†æ¶**ï¼š

- **é€‚åˆ**ï¼šRAGã€å¤æ‚ç¼–æ’ã€å¿«é€ŸåŸå‹ã€å¤šæ•°æ®æºé›†æˆ
- **ä¸é€‚åˆ**ï¼šç®€å•å·¥å…·è°ƒç”¨ã€æ€§èƒ½æ•æ„Ÿåœºæ™¯
- **æœ€ä½³å®è·µ**ï¼šåœ¨éœ€è¦çš„åœ°æ–¹ä½¿ç”¨ LangChainï¼ˆå¦‚ RAGï¼‰ï¼Œç®€å•åœºæ™¯ä½¿ç”¨åŸç”Ÿ Function Calling
- **å­¦ä¹ å»ºè®®**ï¼š
  1. å…ˆæŒæ¡ LangChain åŸºç¡€ç»„ä»¶ï¼ˆPromptsã€Chainsã€Memoryï¼‰
  2. é‡ç‚¹å­¦ä¹  RAG ç›¸å…³åŠŸèƒ½ï¼ˆDocument Loadersã€Vector Storesï¼‰
  3. äº†è§£ LCEL æ–°è¯­æ³•ï¼ˆæ¨èï¼‰
  4. å…³æ³¨ LangGraphï¼ˆMulti-Agent ç¼–æ’ï¼‰

LangChain åœ¨ AI Agent ç”Ÿæ€ä¸­å æ®é‡è¦ä½ç½®ï¼Œå°¤å…¶æ˜¯åœ¨ RAG å’Œå¤æ‚æµç¨‹ç¼–æ’æ–¹é¢ï¼Œä½†ä¸æ˜¯æ‰€æœ‰åœºæ™¯çš„æœ€ä½³é€‰æ‹©ã€‚æ ¹æ®å…·ä½“éœ€æ±‚çµæ´»é€‰æ‹©æŠ€æœ¯æ–¹æ¡ˆï¼Œæ‰æ˜¯æ˜æ™ºä¹‹ä¸¾ã€‚

## LlamaIndex è¯¦è§£

### ä»€ä¹ˆæ˜¯ LlamaIndex

LlamaIndexï¼ˆåŸå GPT Indexï¼‰æ˜¯ä¸€ä¸ªä¸“æ³¨äº**æ•°æ®è¿æ¥å’Œæ£€ç´¢**çš„å¼€æºæ¡†æ¶ï¼Œä¸»è¦ç”¨äºæ„å»º RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰åº”ç”¨ã€‚ä¸ LangChain ç›¸æ¯”ï¼ŒLlamaIndex æ›´ä¸“æ³¨äº**æ•°æ®ç´¢å¼•ã€æ£€ç´¢å’ŒæŸ¥è¯¢**ï¼Œæ˜¯æ„å»ºçŸ¥è¯†åº“å’Œæ–‡æ¡£é—®ç­”ç³»ç»Ÿçš„é¦–é€‰å·¥å…·ã€‚

**æ ¸å¿ƒå®šä½**ï¼šæ•°æ®æ¡†æ¶ï¼ˆData Framework for LLM Applicationsï¼‰

**å®˜æ–¹ä»“åº“**ï¼š`run-llama/llama_index`

**è®¾è®¡å“²å­¦**ï¼š
- LangChainï¼šé€šç”¨çš„ LLM åº”ç”¨æ¡†æ¶ï¼ˆChainã€Agentã€Memory ç­‰ï¼‰
- LlamaIndexï¼šä¸“æ³¨äºæ•°æ®æ‘„å…¥ã€ç´¢å¼•å’Œæ£€ç´¢

#### âš ï¸ åç§°è¯´æ˜ï¼šLlamaIndex vs Llama2

**é‡è¦æ¾„æ¸…**ï¼šLlamaIndex ä¸ Meta çš„ Llama2/Llama3 å¼€æºæ¨¡å‹**æ²¡æœ‰ä»»ä½•å…³ç³»**ï¼Œå®ƒä»¬æ˜¯å®Œå…¨ç‹¬ç«‹çš„é¡¹ç›®ï¼š

| é¡¹ç›® | ç±»å‹ | å¼€å‘è€… | åŠŸèƒ½ |
|-----|------|--------|------|
| **LlamaIndex** | å¼€å‘æ¡†æ¶ | LlamaIndex å›¢é˜Ÿï¼ˆåŸ run-llamaï¼‰ | æ•°æ®ç´¢å¼•å’Œæ£€ç´¢æ¡†æ¶ |
| **Llama2/Llama3** | å¤§è¯­è¨€æ¨¡å‹ | Metaï¼ˆFacebookï¼‰ | å¼€æº LLM æ¨¡å‹ |

**ä¸ºä»€ä¹ˆå« "Llama"ï¼Ÿ**
- LlamaIndex çš„å‘½åæ¥è‡ª"Large Language Model Applications"çš„ç¼©å†™
- ä¸ Meta çš„ Llama æ¨¡å‹çº¯å±å·§åˆï¼ˆå‘½åå†²çªï¼‰

**å®é™…å…³ç³»**ï¼š
- LlamaIndex æ¡†æ¶å¯ä»¥**ä½¿ç”¨** Llama2/Llama3 ä½œä¸ºåº•å±‚ LLM
- ä½† LlamaIndex ä¹Ÿæ”¯æŒ OpenAIã€Claudeã€Gemini ç­‰ä»»ä½• LLM
- ä¸¤è€…æ˜¯"æ¡†æ¶"ä¸"æ¨¡å‹"çš„å…³ç³»ï¼Œè€Œéä»å±å…³ç³»

**ç¤ºä¾‹**ï¼š
```python
# LlamaIndex æ¡†æ¶ + Llama2 æ¨¡å‹
from llama_index.llms.ollama import Ollama
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# ä½¿ç”¨æœ¬åœ° Llama2 æ¨¡å‹
llm = Ollama(model="llama2")

# LlamaIndex æ¡†æ¶è¿›è¡Œç´¢å¼•å’Œæ£€ç´¢
documents = SimpleDirectoryReader("./data").load_data()
index = VectorStoreIndex.from_documents(documents)

# æŸ¥è¯¢ï¼ˆåº•å±‚è°ƒç”¨ Llama2ï¼‰
query_engine = index.as_query_engine(llm=llm)
response = query_engine.query("é—®é¢˜")
```

**æ€»ç»“**ï¼š
- âŒ **ä¸æ˜¯**ï¼šLlamaIndex ä¸æ˜¯ Llama2 çš„é…å¥—å·¥å…·
- âŒ **ä¸æ˜¯**ï¼šLlamaIndex ä¸æ˜¯åªèƒ½ç”¨ Llama æ¨¡å‹
- âœ… **æ˜¯**ï¼šLlamaIndex æ˜¯é€šç”¨çš„ RAG æ¡†æ¶ï¼Œå¯ä»¥ä½¿ç”¨ä»»ä½• LLMï¼ˆåŒ…æ‹¬ Llama2ï¼‰

### æ ¸å¿ƒæ¦‚å¿µ

#### 1. **Documentsï¼ˆæ–‡æ¡£ï¼‰**

åŸå§‹æ•°æ®çš„å®¹å™¨ï¼š

```python
from llama_index.core import Document

# åˆ›å»ºæ–‡æ¡£
doc1 = Document(
    text="LlamaIndex æ˜¯ä¸€ä¸ªæ•°æ®æ¡†æ¶...",
    metadata={
        "author": "å¼ ä¸‰",
        "date": "2025-11-19",
        "category": "æŠ€æœ¯æ–‡æ¡£"
    }
)

# ä»æ–‡ä»¶åŠ è½½
from llama_index.core import SimpleDirectoryReader

documents = SimpleDirectoryReader("./data").load_data()
```

#### 2. **Nodesï¼ˆèŠ‚ç‚¹ï¼‰**

æ–‡æ¡£åˆ‡åˆ†åçš„åŸºæœ¬å•å…ƒï¼š

```python
from llama_index.core.node_parser import SentenceSplitter

# åˆ‡åˆ†æ–‡æ¡£
parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)
nodes = parser.get_nodes_from_documents(documents)

# èŠ‚ç‚¹åŒ…å«ï¼š
# - text: æ–‡æœ¬å†…å®¹
# - metadata: å…ƒæ•°æ®
# - relationships: ä¸å…¶ä»–èŠ‚ç‚¹çš„å…³ç³»
```

#### 3. **Indexï¼ˆç´¢å¼•ï¼‰**

æ•°æ®çš„ç»„ç»‡ç»“æ„ï¼Œæ”¯æŒé«˜æ•ˆæ£€ç´¢ï¼š

```python
from llama_index.core import VectorStoreIndex, SummaryIndex, TreeIndex

# å‘é‡ç´¢å¼•ï¼ˆæœ€å¸¸ç”¨ï¼‰
vector_index = VectorStoreIndex.from_documents(documents)

# æ‘˜è¦ç´¢å¼•
summary_index = SummaryIndex.from_documents(documents)

# æ ‘ç´¢å¼•
tree_index = TreeIndex.from_documents(documents)
```

#### 4. **Query Engineï¼ˆæŸ¥è¯¢å¼•æ“ï¼‰**

å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„æ¥å£ï¼š

```python
# åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine()

# æŸ¥è¯¢
response = query_engine.query("LlamaIndex çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

#### 5. **Chat Engineï¼ˆå¯¹è¯å¼•æ“ï¼‰**

æ”¯æŒå¤šè½®å¯¹è¯çš„æŸ¥è¯¢æ¥å£ï¼š

```python
# åˆ›å»ºå¯¹è¯å¼•æ“
chat_engine = index.as_chat_engine()

# å¤šè½®å¯¹è¯
response1 = chat_engine.chat("LlamaIndex æ˜¯ä»€ä¹ˆï¼Ÿ")
response2 = chat_engine.chat("å®ƒå’Œ LangChain æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ")  # ä¿æŒä¸Šä¸‹æ–‡
```

### å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

```python
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# 1. åŠ è½½æ•°æ®
documents = SimpleDirectoryReader("./data").load_data()

# 2. åˆ›å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(documents)

# 3. æŸ¥è¯¢
query_engine = index.as_query_engine()
response = query_engine.query("æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)

# 4. æŒä¹…åŒ–ç´¢å¼•
index.storage_context.persist(persist_dir="./storage")

# 5. åŠ è½½ç´¢å¼•
from llama_index.core import load_index_from_storage, StorageContext

storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)
```

### ä¸»è¦ç´¢å¼•ç±»å‹

#### 1. **VectorStoreIndexï¼ˆå‘é‡ç´¢å¼•ï¼‰**

æœ€å¸¸ç”¨çš„ç´¢å¼•ç±»å‹ï¼Œä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ï¼š

```python
from llama_index.core import VectorStoreIndex

index = VectorStoreIndex.from_documents(documents)

# é…ç½®æ£€ç´¢å‚æ•°
query_engine = index.as_query_engine(
    similarity_top_k=5,  # è¿”å›å‰5ä¸ªæœ€ç›¸å…³ç»“æœ
    response_mode="compact"  # å“åº”æ¨¡å¼
)

response = query_engine.query("æŸ¥è¯¢å†…å®¹")
```

#### 2. **SummaryIndexï¼ˆæ‘˜è¦ç´¢å¼•ï¼‰**

é€‚åˆéœ€è¦éå†æ‰€æœ‰æ–‡æ¡£çš„åœºæ™¯ï¼š

```python
from llama_index.core import SummaryIndex

index = SummaryIndex.from_documents(documents)

# ä¼šè€ƒè™‘æ‰€æœ‰æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ
query_engine = index.as_query_engine()
response = query_engine.query("æ€»ç»“æ‰€æœ‰æ–‡æ¡£çš„å†…å®¹")
```

#### 3. **TreeIndexï¼ˆæ ‘ç´¢å¼•ï¼‰**

å±‚æ¬¡åŒ–çš„ç´¢å¼•ç»“æ„ï¼š

```python
from llama_index.core import TreeIndex

index = TreeIndex.from_documents(documents)

# ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œè‡ªä¸Šè€Œä¸‹æŸ¥è¯¢
query_engine = index.as_query_engine()
response = query_engine.query("æŸ¥è¯¢å†…å®¹")
```

#### 4. **KeywordTableIndexï¼ˆå…³é”®è¯ç´¢å¼•ï¼‰**

åŸºäºå…³é”®è¯åŒ¹é…ï¼š

```python
from llama_index.core import KeywordTableIndex

index = KeywordTableIndex.from_documents(documents)

query_engine = index.as_query_engine()
response = query_engine.query("Python")  # åŒ¹é…åŒ…å« "Python" çš„æ–‡æ¡£
```

### é«˜çº§ç‰¹æ€§

#### 1. **è‡ªå®šä¹‰ LLM å’Œ Embedding**

```python
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import Settings

# é…ç½® LLM
Settings.llm = OpenAI(model="gpt-4", temperature=0.1)

# é…ç½® Embedding
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-large")

# åˆ›å»ºç´¢å¼•ï¼ˆä¼šä½¿ç”¨ä¸Šè¿°é…ç½®ï¼‰
index = VectorStoreIndex.from_documents(documents)
```

#### 2. **é›†æˆå‘é‡æ•°æ®åº“**

```python
# Chroma
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb

chroma_client = chromadb.PersistentClient(path="./chroma_db")
chroma_collection = chroma_client.create_collection("my_collection")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)

# ä½¿ç”¨å‘é‡å­˜å‚¨åˆ›å»ºç´¢å¼•
from llama_index.core import StorageContext

storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context
)

# Pinecone
from llama_index.vector_stores.pinecone import PineconeVectorStore
import pinecone

pinecone.init(api_key="your-api-key", environment="us-west1-gcp")
pinecone_index = pinecone.Index("my-index")
vector_store = PineconeVectorStore(pinecone_index=pinecone_index)

# Weaviateã€Milvusã€Qdrant ç­‰éƒ½æ”¯æŒ
```

#### 3. **è‡ªå®šä¹‰ Prompt**

```python
from llama_index.core import PromptTemplate

# è‡ªå®šä¹‰æŸ¥è¯¢æç¤ºæ¨¡æ¿
qa_prompt_tmpl = (
    "ä¸Šä¸‹æ–‡ä¿¡æ¯å¦‚ä¸‹ï¼š\n"
    "---------------------\n"
    "{context_str}\n"
    "---------------------\n"
    "åŸºäºä¸Šè¿°ä¿¡æ¯ï¼ˆä¸è¦ä½¿ç”¨å…ˆéªŒçŸ¥è¯†ï¼‰ï¼Œå›ç­”é—®é¢˜ï¼š{query_str}\n"
)

qa_prompt = PromptTemplate(qa_prompt_tmpl)

# ä½¿ç”¨è‡ªå®šä¹‰æç¤º
query_engine = index.as_query_engine(
    text_qa_template=qa_prompt
)
```

#### 4. **Retrieverï¼ˆæ£€ç´¢å™¨ï¼‰**

æ›´çµæ´»çš„æ£€ç´¢æ§åˆ¶ï¼š

```python
from llama_index.core.retrievers import VectorIndexRetriever

# åˆ›å»ºæ£€ç´¢å™¨
retriever = VectorIndexRetriever(
    index=index,
    similarity_top_k=10,
)

# æ£€ç´¢
nodes = retriever.retrieve("æŸ¥è¯¢å†…å®¹")

# è‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“
from llama_index.core.query_engine import RetrieverQueryEngine

query_engine = RetrieverQueryEngine(retriever=retriever)
response = query_engine.query("æŸ¥è¯¢å†…å®¹")
```

#### 5. **Re-rankingï¼ˆé‡æ’åºï¼‰**

æé«˜æ£€ç´¢è´¨é‡ï¼š

```python
from llama_index.core.postprocessor import SimilarityPostprocessor

# åˆ›å»ºåå¤„ç†å™¨
postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)

# åº”ç”¨åˆ°æŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine(
    node_postprocessors=[postprocessor]
)
```

#### 6. **Sub-Question Query Engineï¼ˆå­é—®é¢˜æŸ¥è¯¢ï¼‰**

å°†å¤æ‚é—®é¢˜åˆ†è§£ï¼š

```python
from llama_index.core.query_engine import SubQuestionQueryEngine
from llama_index.core.tools import QueryEngineTool

# åˆ›å»ºå¤šä¸ªä¸“ä¸šç´¢å¼•
tech_index = VectorStoreIndex.from_documents(tech_docs)
business_index = VectorStoreIndex.from_documents(business_docs)

# å®šä¹‰å·¥å…·
query_engine_tools = [
    QueryEngineTool(
        query_engine=tech_index.as_query_engine(),
        metadata={"name": "tech", "description": "æŠ€æœ¯æ–‡æ¡£"}
    ),
    QueryEngineTool(
        query_engine=business_index.as_query_engine(),
        metadata={"name": "business", "description": "å•†ä¸šæ–‡æ¡£"}
    ),
]

# åˆ›å»ºå­é—®é¢˜æŸ¥è¯¢å¼•æ“
query_engine = SubQuestionQueryEngine.from_defaults(
    query_engine_tools=query_engine_tools
)

# å¤æ‚æŸ¥è¯¢ä¼šè‡ªåŠ¨åˆ†è§£
response = query_engine.query(
    "æ¯”è¾ƒæŠ€æœ¯æ–¹æ¡ˆå’Œå•†ä¸šæ¨¡å¼çš„ä¼˜åŠ£"
)
```

### å®æˆ˜ç¤ºä¾‹ï¼šå®Œæ•´çš„æ–‡æ¡£é—®ç­”ç³»ç»Ÿ

```python
from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    StorageContext,
    load_index_from_storage,
)
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import Settings
import os

class DocumentQASystem:
    def __init__(self, data_dir: str, persist_dir: str = "./storage"):
        self.data_dir = data_dir
        self.persist_dir = persist_dir
        
        # é…ç½®
        Settings.llm = OpenAI(model="gpt-4", temperature=0)
        Settings.embed_model = OpenAIEmbedding()
        
        self.index = None
        self.query_engine = None
        
    def build_index(self):
        """æ„å»ºç´¢å¼•"""
        # åŠ è½½æ–‡æ¡£
        documents = SimpleDirectoryReader(self.data_dir).load_data()
        
        # åˆ›å»ºç´¢å¼•
        self.index = VectorStoreIndex.from_documents(documents)
        
        # æŒä¹…åŒ–
        self.index.storage_context.persist(persist_dir=self.persist_dir)
        
        print(f"ç´¢å¼•å·²åˆ›å»ºï¼Œå…± {len(documents)} ä¸ªæ–‡æ¡£")
        
    def load_index(self):
        """åŠ è½½å·²æœ‰ç´¢å¼•"""
        if not os.path.exists(self.persist_dir):
            raise ValueError("ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")
        
        storage_context = StorageContext.from_defaults(
            persist_dir=self.persist_dir
        )
        self.index = load_index_from_storage(storage_context)
        
        print("ç´¢å¼•å·²åŠ è½½")
        
    def create_query_engine(self, similarity_top_k: int = 3):
        """åˆ›å»ºæŸ¥è¯¢å¼•æ“"""
        if self.index is None:
            raise ValueError("è¯·å…ˆåŠ è½½æˆ–æ„å»ºç´¢å¼•")
        
        self.query_engine = self.index.as_query_engine(
            similarity_top_k=similarity_top_k,
            response_mode="compact"
        )
        
    def query(self, question: str):
        """æŸ¥è¯¢"""
        if self.query_engine is None:
            self.create_query_engine()
        
        response = self.query_engine.query(question)
        
        # è¿”å›ç­”æ¡ˆå’Œæ¥æº
        return {
            "answer": str(response),
            "source_nodes": [
                {
                    "text": node.node.text[:200] + "...",
                    "score": node.score,
                    "metadata": node.node.metadata
                }
                for node in response.source_nodes
            ]
        }

# ä½¿ç”¨
qa_system = DocumentQASystem(data_dir="./docs")

# é¦–æ¬¡ä½¿ç”¨ï¼šæ„å»ºç´¢å¼•
qa_system.build_index()

# åç»­ä½¿ç”¨ï¼šåŠ è½½ç´¢å¼•
# qa_system.load_index()

# æŸ¥è¯¢
result = qa_system.query("LlamaIndex çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ")
print(result["answer"])
print("\næ¥æºï¼š")
for i, source in enumerate(result["source_nodes"], 1):
    print(f"{i}. åˆ†æ•°: {source['score']:.2f}")
    print(f"   å†…å®¹: {source['text']}")
```

### LlamaIndex vs LangChain

| ç»´åº¦ | LlamaIndex | LangChain |
|-----|-----------|-----------|
| **æ ¸å¿ƒå®šä½** | æ•°æ®æ¡†æ¶ï¼ˆRAG ä¸“å®¶ï¼‰ | é€šç”¨ LLM æ¡†æ¶ |
| **ä¸»è¦ç”¨é€”** | æ•°æ®ç´¢å¼•ã€æ£€ç´¢ã€æŸ¥è¯¢ | Chainã€Agentã€Memory å…¨æ ˆ |
| **RAG èƒ½åŠ›** | â­â­â­â­â­ æœ€å¼º | â­â­â­â­ å®Œå–„ |
| **Agent èƒ½åŠ›** | â­â­â­ åŸºç¡€æ”¯æŒ | â­â­â­â­â­ å…¨é¢ |
| **å­¦ä¹ æ›²çº¿** | è¾ƒå¹³ç¼“ï¼ˆä¸“æ³¨ RAGï¼‰ | é™¡å³­ï¼ˆæ¦‚å¿µå¤šï¼‰ |
| **æ–‡æ¡£è´¨é‡** | ä¼˜ç§€ | è‰¯å¥½ |
| **é€‚ç”¨åœºæ™¯** | æ–‡æ¡£é—®ç­”ã€çŸ¥è¯†åº“ | å¤æ‚ Agentã€å¤šæ­¥éª¤æµç¨‹ |
| **ç”Ÿæ€ç³»ç»Ÿ** | ä¸°å¯Œï¼ˆæ•°æ®è¿æ¥å™¨ï¼‰ | æå…¶ä¸°å¯Œï¼ˆå„ç±»é›†æˆï¼‰ |

### ä½¿ç”¨åœºæ™¯å»ºè®®

**ä¼˜å…ˆé€‰æ‹© LlamaIndexï¼š**

1. âœ… **æ–‡æ¡£é—®ç­”ç³»ç»Ÿ**
   - ä¼ä¸šçŸ¥è¯†åº“
   - æŠ€æœ¯æ–‡æ¡£æŸ¥è¯¢
   - æ³•å¾‹/åŒ»ç–—æ–‡æ¡£åˆ†æ

2. âœ… **RAG åº”ç”¨**
   - éœ€è¦å¼•ç”¨æ¥æºçš„å›ç­”
   - å¤§é‡æ–‡æ¡£çš„è¯­ä¹‰æ£€ç´¢
   - ç»“æ„åŒ–+éç»“æ„åŒ–æ•°æ®æŸ¥è¯¢

3. âœ… **æ•°æ®å¯†é›†å‹åº”ç”¨**
   - PDFã€Wordã€Excel ç­‰å¤šæ ¼å¼æ•°æ®
   - éœ€è¦è‡ªå®šä¹‰ç´¢å¼•ç»“æ„
   - å¤æ‚çš„æ£€ç´¢ç­–ç•¥

**ä¼˜å…ˆé€‰æ‹© LangChainï¼š**

1. âœ… **Agent åº”ç”¨**
   - éœ€è¦åŠ¨æ€å·¥å…·è°ƒç”¨
   - å¤šæ­¥éª¤å†³ç­–æµç¨‹
   - å¤æ‚çš„ä»»åŠ¡ç¼–æ’

2. âœ… **å¯¹è¯ç³»ç»Ÿ**
   - å¤šè½®å¯¹è¯ç®¡ç†
   - ä¸Šä¸‹æ–‡è®°å¿†
   - ä¸ªæ€§åŒ–åŠ©æ‰‹

3. âœ… **å·¥ä½œæµè‡ªåŠ¨åŒ–**
   - Chain ç»„åˆ
   - æ¡ä»¶åˆ†æ”¯
   - å¾ªç¯å’Œè¿­ä»£

**æ··åˆä½¿ç”¨ï¼š**

```python
# LlamaIndex åšæ£€ç´¢ï¼ŒLangChain åš Agent
from llama_index.core import VectorStoreIndex
from langchain.tools import Tool
from langchain.agents import initialize_agent

# 1. LlamaIndex ç´¢å¼•
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()

# 2. åŒ…è£…æˆ LangChain å·¥å…·
def search_docs(query: str) -> str:
    response = query_engine.query(query)
    return str(response)

search_tool = Tool(
    name="DocumentSearch",
    func=search_docs,
    description="åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ä¿¡æ¯"
)

# 3. LangChain Agent
agent = initialize_agent(
    tools=[search_tool],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)

# 4. æ‰§è¡Œ
result = agent.run("æŸ¥è¯¢å¹¶æ€»ç»“æ–‡æ¡£ä¸­å…³äº AI çš„å†…å®¹")
```

### LlamaIndex ç”Ÿæ€

**æ•°æ®è¿æ¥å™¨ï¼ˆData Loadersï¼‰**ï¼š

- **æ–‡æ¡£**ï¼šPDFã€Wordã€Markdownã€HTML
- **æ•°æ®åº“**ï¼šPostgreSQLã€MySQLã€MongoDB
- **API**ï¼šNotionã€Google Docsã€Slackã€GitHub
- **ç½‘é¡µ**ï¼šBeautifulSoupã€Selenium
- **éŸ³è§†é¢‘**ï¼šWhisperï¼ˆè¯­éŸ³è½¬æ–‡æœ¬ï¼‰

**å‘é‡æ•°æ®åº“é›†æˆ**ï¼š

- Chromaã€Pineconeã€Weaviateã€Milvusã€Qdrantã€FAISS

**LLM é›†æˆ**ï¼š

- OpenAIã€Anthropicã€Googleã€Azureã€æœ¬åœ°æ¨¡å‹ï¼ˆOllamaã€Llama.cppï¼‰

### æ€»ç»“

**LlamaIndex çš„æ ¸å¿ƒä¼˜åŠ¿**ï¼š

1. âœ… **RAG ä¸“å®¶**ï¼šä¸“ä¸ºæ•°æ®ç´¢å¼•å’Œæ£€ç´¢ä¼˜åŒ–
2. âœ… **æ˜“ç”¨æ€§**ï¼šAPI è®¾è®¡ç®€æ´ï¼Œå­¦ä¹ æ›²çº¿å¹³ç¼“
3. âœ… **æ•°æ®è¿æ¥å™¨ä¸°å¯Œ**ï¼šæ”¯æŒå„ç§æ•°æ®æº
4. âœ… **æ£€ç´¢è´¨é‡é«˜**ï¼šå†…ç½®å¤šç§ä¼˜åŒ–ç­–ç•¥
5. âœ… **ä¸ LangChain äº’è¡¥**ï¼šå¯ä»¥æ··åˆä½¿ç”¨

**é€‚åˆ LlamaIndex çš„å›¢é˜Ÿ**ï¼š

- ä¸»è¦éœ€æ±‚æ˜¯æ–‡æ¡£é—®ç­”å’ŒçŸ¥è¯†åº“
- å¸Œæœ›å¿«é€Ÿä¸Šæ‰‹ RAG åº”ç”¨
- éœ€è¦é«˜è´¨é‡çš„æ£€ç´¢å’Œå¼•ç”¨
- ä¸éœ€è¦å¤æ‚çš„ Agent åŠŸèƒ½

**æŠ€æœ¯é€‰å‹å»ºè®®**ï¼š

- **çº¯ RAG åº”ç”¨** â†’ LlamaIndexï¼ˆé¦–é€‰ï¼‰
- **å¤æ‚ Agent + RAG** â†’ LangChain + LlamaIndexï¼ˆæ··åˆï¼‰
- **é€šç”¨ LLM åº”ç”¨** â†’ LangChainï¼ˆé¦–é€‰ï¼‰

LlamaIndex åœ¨ RAG é¢†åŸŸæ˜¯æœ€ä¸“ä¸šçš„å·¥å…·ï¼Œå¦‚æœä½ çš„æ ¸å¿ƒéœ€æ±‚æ˜¯æ–‡æ¡£é—®ç­”å’ŒçŸ¥è¯†åº“ï¼ŒLlamaIndex æ˜¯æ¯” LangChain æ›´å¥½çš„é€‰æ‹©ã€‚

## AI agent development
### å¸¸ç”¨æŠ€æœ¯æ ˆ

- 1. ç¼–ç¨‹è¯­è¨€
- Pythonï¼ˆä¸»æµï¼Œç”Ÿæ€ä¸°å¯Œï¼‰
- JavaScript/TypeScriptï¼ˆWeb/Node.js Agentï¼‰
- Goã€Javaï¼ˆé«˜æ€§èƒ½/ä¼ä¸šçº§ï¼‰
- Pythonï¼ˆä¸»æµï¼Œç”Ÿæ€ä¸°å¯Œï¼‰
- JavaScript/TypeScriptï¼ˆWeb/Node.js Agentï¼‰
- Goã€Javaï¼ˆé«˜æ€§èƒ½/ä¼ä¸šçº§ï¼‰
@@

- 1. å¤§è¯­è¨€æ¨¡å‹ä¸ API
- OpenAI GPT-4/3.5ã€Claudeã€Llama
- Hugging Face Transformers
- LangChainã€LlamaIndexï¼ˆAgent æ¡†æ¶ï¼‰
- OpenAI GPT-4/3.5ã€Claudeã€Llama
- Hugging Face Transformers
- LangChainã€LlamaIndexï¼ˆAgent æ¡†æ¶ï¼‰
@@

- 1. Web æ¡†æ¶ä¸æœåŠ¡
- FastAPIã€Flaskï¼ˆPythonï¼‰
- Express.jsï¼ˆNode.jsï¼‰
- Django
- FastAPIã€Flaskï¼ˆPythonï¼‰
- Express.jsï¼ˆNode.jsï¼‰
- Django
@@

- 1. æ•°æ®å­˜å‚¨
- Redisã€MongoDBã€PostgreSQLã€SQLite
- å‘é‡æ•°æ®åº“ï¼šMilvusã€Pineconeã€Weaviate
- Redisã€MongoDBã€PostgreSQLã€SQLite
- å‘é‡æ•°æ®åº“ï¼šMilvusã€Pineconeã€Weaviate
@@

- 1. æ¶ˆæ¯é˜Ÿåˆ—ä¸å¼‚æ­¥ä»»åŠ¡
- Celeryã€RabbitMQã€Kafka
- Celeryã€RabbitMQã€Kafka
@@

- 1. å®¹å™¨ä¸éƒ¨ç½²
- Dockerã€Kubernetes
- äº‘æœåŠ¡ï¼šAWSã€Azureã€GCP
- Dockerã€Kubernetes
- äº‘æœåŠ¡ï¼šAWSã€Azureã€GCP
@@

- 1. å‰ç«¯äº¤äº’
- Reactã€Vue.js
- WebSocketã€RESTful API
- Reactã€Vue.js
- WebSocketã€RESTful API
@@

- 1. å…¶ä»–
- Prompt å·¥ç¨‹ã€å·¥å…·æ’ä»¶ç³»ç»Ÿ
- OAuth2ã€JWTï¼ˆå®‰å…¨è®¤è¯ï¼‰
- æ—¥å¿—ä¸ç›‘æ§ï¼šPrometheusã€Grafana
- Prompt å·¥ç¨‹ã€å·¥å…·æ’ä»¶ç³»ç»Ÿ
- OAuth2ã€JWTï¼ˆå®‰å…¨è®¤è¯ï¼‰
- æ—¥å¿—ä¸ç›‘æ§ï¼šPrometheusã€Grafana

## æœ¯è¯­ä¸ç¼©å†™å¯¹ç…§è¡¨

### æ ¸å¿ƒæ¦‚å¿µ

| æœ¯è¯­/ç¼©å†™ | å…¨ç§° | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|---------|------|---------|------|
| **AI Agent** | Artificial Intelligence Agent | äººå·¥æ™ºèƒ½ä»£ç† | èƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒã€åšå‡ºå†³ç­–å¹¶æ‰§è¡ŒåŠ¨ä½œçš„æ™ºèƒ½ç³»ç»Ÿ |
| **LLM** | Large Language Model | å¤§è¯­è¨€æ¨¡å‹ | åœ¨æµ·é‡æ–‡æœ¬æ•°æ®ä¸Šè®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¦‚ GPTã€Claude |
| **NLU** | Natural Language Understanding | è‡ªç„¶è¯­è¨€ç†è§£ | ä½¿è®¡ç®—æœºç†è§£äººç±»è¯­è¨€å«ä¹‰ã€æ„å›¾å’Œä¸Šä¸‹æ–‡çš„æŠ€æœ¯ |
| **NLP** | Natural Language Processing | è‡ªç„¶è¯­è¨€å¤„ç† | å¤„ç†å’Œåˆ†æäººç±»è¯­è¨€çš„è®¡ç®—æœºæŠ€æœ¯é¢†åŸŸ |

### åè®®ä¸æ ‡å‡†

| æœ¯è¯­/ç¼©å†™ | å…¨ç§° | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|---------|------|---------|------|
| **A2A** | Agent-to-Agent Protocol | ä»£ç†é—´é€šä¿¡åè®® | AI Agent ä¹‹é—´é€šä¿¡å’Œåä½œçš„æ ‡å‡†åŒ–åè®® |
| **MCP** | Model Context Protocol | æ¨¡å‹ä¸Šä¸‹æ–‡åè®® | Agent ä¸å·¥å…·/æ•°æ®æºè¿æ¥çš„æ ‡å‡†åè®® |
| **LSP** | Language Server Protocol | è¯­è¨€æœåŠ¡å™¨åè®® | ç¼–è¾‘å™¨ä¸è¯­è¨€æœåŠ¡å™¨ä¹‹é—´çš„é€šä¿¡åè®® |
| **JSON-RPC** | JSON Remote Procedure Call | JSON è¿œç¨‹è¿‡ç¨‹è°ƒç”¨ | åŸºäº JSON çš„è¿œç¨‹è¿‡ç¨‹è°ƒç”¨åè®® |

### AI Agent æŠ€æœ¯

| æœ¯è¯­/ç¼©å†™ | å…¨ç§° | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|---------|------|---------|------|
| **RAG** | Retrieval-Augmented Generation | æ£€ç´¢å¢å¼ºç”Ÿæˆ | ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„ AI æŠ€æœ¯ï¼Œæé«˜ç­”æ¡ˆå‡†ç¡®æ€§ |
| **Function Calling** | - | å‡½æ•°è°ƒç”¨ | LLM è¯†åˆ«æ„å›¾å¹¶è°ƒç”¨å¤–éƒ¨å‡½æ•°/å·¥å…·çš„èƒ½åŠ› |
| **Tool Use** | - | å·¥å…·ä½¿ç”¨ | Agent è°ƒç”¨å¤–éƒ¨å·¥å…·å®Œæˆç‰¹å®šä»»åŠ¡çš„èƒ½åŠ› |
| **Slot Filling** | - | æ§½ä½å¡«å…… | ä»ç”¨æˆ·è¾“å…¥ä¸­æå–ç‰¹å®šå‚æ•°çš„è¿‡ç¨‹ |
| **Intent Recognition** | - | æ„å›¾è¯†åˆ« | è¯†åˆ«ç”¨æˆ·è¾“å…¥æ„å›¾å¹¶åˆ†ç±»çš„è¿‡ç¨‹ |

### å¼€å‘æ¡†æ¶ä¸å·¥å…·

| æœ¯è¯­/ç¼©å†™ | å…¨ç§° | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|---------|------|---------|------|
| **SDK** | Software Development Kit | è½¯ä»¶å¼€å‘å·¥å…·åŒ… | ç”¨äºå¼€å‘ç‰¹å®šè½¯ä»¶çš„å·¥å…·é›†åˆ |
| **API** | Application Programming Interface | åº”ç”¨ç¨‹åºæ¥å£ | ä¸åŒè½¯ä»¶ç»„ä»¶ä¹‹é—´äº¤äº’çš„æ¥å£ |
| **WebSocket** | - | ç½‘ç»œå¥—æ¥å­— | æ”¯æŒåŒå‘å®æ—¶é€šä¿¡çš„ç½‘ç»œåè®® |
| **SSE** | Server-Sent Events | æœåŠ¡å™¨æ¨é€äº‹ä»¶ | æœåŠ¡å™¨å‘å®¢æˆ·ç«¯æ¨é€æ•°æ®çš„æŠ€æœ¯ |
| **REST** | Representational State Transfer | è¡¨è¿°æ€§çŠ¶æ€è½¬ç§» | ä¸€ç§ Web æœåŠ¡æ¶æ„é£æ ¼ |

### è®¤è¯ä¸å®‰å…¨

| æœ¯è¯­/ç¼©å†™ | å…¨ç§° | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|---------|------|---------|------|
| **OAuth2** | Open Authorization 2.0 | å¼€æ”¾æˆæƒ 2.0 | å¼€æ”¾çš„æˆæƒæ ‡å‡†ï¼Œå…è®¸ç¬¬ä¸‰æ–¹åº”ç”¨è®¿é—®èµ„æº |
| **JWT** | JSON Web Token | JSON Web ä»¤ç‰Œ | ç”¨äºèº«ä»½éªŒè¯å’Œä¿¡æ¯äº¤æ¢çš„å¼€æ”¾æ ‡å‡† |
| **API Key** | - | API å¯†é’¥ | ç”¨äºéªŒè¯ API è°ƒç”¨è€…èº«ä»½çš„å¯†é’¥ |

### æ•°æ®ä¸å­˜å‚¨

| æœ¯è¯­/ç¼©å†™ | å…¨ç§° | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|---------|------|---------|------|
| **Vector DB** | Vector Database | å‘é‡æ•°æ®åº“ | ä¸“é—¨å­˜å‚¨å’Œæ£€ç´¢å‘é‡åµŒå…¥çš„æ•°æ®åº“ |
| **Embedding** | - | åµŒå…¥/å‘é‡åŒ– | å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡çš„è¿‡ç¨‹ |
| **NoSQL** | Not Only SQL | éå…³ç³»å‹æ•°æ®åº“ | éä¼ ç»Ÿå…³ç³»å‹æ•°æ®åº“çš„ç»Ÿç§° |

### éƒ¨ç½²ä¸è¿ç»´

| æœ¯è¯­/ç¼©å†™ | å…¨ç§° | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|---------|------|---------|------|
| **CI/CD** | Continuous Integration/Continuous Deployment | æŒç»­é›†æˆ/æŒç»­éƒ¨ç½² | è‡ªåŠ¨åŒ–è½¯ä»¶å¼€å‘å’Œéƒ¨ç½²æµç¨‹ |
| **K8s** | Kubernetes | - | å®¹å™¨ç¼–æ’å¹³å°ï¼ˆ8 ä»£è¡¨ä¸­é—´çœç•¥çš„ 8 ä¸ªå­—æ¯ï¼‰ |
| **Container** | - | å®¹å™¨ | è½»é‡çº§ã€å¯ç§»æ¤çš„è½¯ä»¶è¿è¡Œç¯å¢ƒ |

### å¸¸è§åœºæ™¯æœ¯è¯­

| æœ¯è¯­ | ä¸­æ–‡é‡Šä¹‰ | è¯´æ˜ |
|-----|---------|------|
| **Prompt Engineering** | æç¤ºè¯å·¥ç¨‹ | è®¾è®¡å’Œä¼˜åŒ– LLM è¾“å…¥æç¤ºçš„æŠ€æœ¯ |
| **Context Window** | ä¸Šä¸‹æ–‡çª—å£ | LLM èƒ½å¤Ÿå¤„ç†çš„æœ€å¤§è¾“å…¥æ–‡æœ¬é•¿åº¦ |
| **Token** | è¯å…ƒ/æ ‡è®° | LLM å¤„ç†æ–‡æœ¬çš„åŸºæœ¬å•ä½ |
| **Temperature** | æ¸©åº¦å‚æ•° | æ§åˆ¶ LLM è¾“å‡ºéšæœºæ€§çš„å‚æ•° |
| **Streaming** | æµå¼è¾“å‡º | é€æ­¥è¿”å›ç»“æœè€Œéä¸€æ¬¡æ€§è¿”å› |
| **Multi-turn Conversation** | å¤šè½®å¯¹è¯ | æ”¯æŒä¸Šä¸‹æ–‡è¿ç»­çš„å¯¹è¯äº¤äº’ |
