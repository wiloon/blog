---
title: ETL
author: "-"
date: 2015-01-08T06:54:27+00:00
url: /?p=7211
categories:
  - Inbox
tags:
  - ETL

---
## ETL
http://baike.baidu.com/subview/69207/14676359.htm

ETL,是英文 Extract-Transform-Load 的缩写,用来描述将数据从来源端经过萃取 (extract) 、转置 (transform) 、加载 (load) 至目的端的过程。ETL一词较常用在数据仓库,但其对象并不限于数据仓库。
  
ETL是构建数据仓库的重要一环,用户从数据源抽取出所需的数据,经过数据清洗,最终按照预先定义好的数据仓库模型,将数据加载到数据仓库中去。
  
信息是现代企业的重要资源,是企业运用科学管理、决策分析的基础。目前,大多数企业花费大量的资金和时间来构建联机事务处理OLTP的业务系统和办公自动化系统,用来记录事务处理的各种相关数据。据统计,数据量每2～3年时间就会成倍增长,这些数据蕴含着巨大的商业价值,而企业所关注的通常只占在总数据量的2%～4%左右。因此,企业仍然没有最大化地利用已存在的数据资源,以致于浪费了更多的时间和资金,也失去制定关键商业决策的最佳契机。于是,企业如何通过各种技术手段,并把数据转换为信息、知识,已经成了提高其核心竞争力的主要瓶颈。而ETL则是主要的一个技术手段。目前,ETL工具的典型代表有:Informatica、Datastage、OWB、微软DTS、Beeload、Kettle、久其ETL……
  
开源的工具有eclipse的etl插件。cloveretl.
  
数据集成: 快速实现ETL
  
ETL的质量问题具体表现为正确性、完整性、一致性、完备性、有效性、时效性和可获取性等几个特性。而影响质量问题的原因有很多,由系统集成和历史数据造成的原因主要包括:业务系统不同时期系统之间数据模型不一致；业务系统不同时期业务过程有变化；旧系统模块在运营、人事、财务、办公系统等相关信息的不一致；遗留系统和新业务、管理系统数据集成不完备带来的不一致性。
  
实现ETL,首先要实现ETL转换的过程。体现为以下几个方面: 
  
1. 空值处理: 可捕获字段空值,进行加载或替换为其他含义数据,并可根据字段空值实现分流加载到不同目标库。
  
2. 规范化数据格式: 可实现字段格式约束定义,对于数据源中时间、数值、字符等数据,可自定义加载格式。
  
3. 拆分数据: 依据业务需求对字段可进行分解。例,主叫号 861082585313-8148,可进行区域码和电话号码分解。
  
4. 验证数据正确性: 可利用Lookup及拆分功能进行数据验证。例如,主叫号861082585313-8148,进行区域码和电话号码分解后,可利用Lookup返回主叫网关或交换机记载的主叫地区,进行数据验证。
  
5. 数据替换: 对于因业务因素,可实现无效数据、缺失数据的替换。
  
6. Lookup: 查获丢失数据 Lookup实现子查询,并返回用其他手段获取的缺失字段,保证字段完整性。
  
7. 建立ETL过程的主外键约束: 对无依赖性的非法数据,可替换或导出到错误数据文件中,保证主键唯一记录的加载。为了能更好地实现ETL,笔者建议用户在实施ETL过程中应注意以下几点: 
  
第一,如果条件允许,可利用数据中转区对运营数据进行预处理,保证集成与加载的高效性；
  
第二,如果ETL的过程是主动"拉取",而不是从内部"推送",其可控性将大为增强；
  
第三,ETL之前应制定流程化的配置管理和标准协议；
  
第四,关键数据标准至关重要。ETL面临的最大挑战是当接收数据时其各源数据的异构性和低质量。以电信为例,A系统按照统计代码管理数据,B系统按照账目数字管理,C系统按照语音ID管理。当ETL需要对这三个系统进行集成以获得对客户的全面视角时,这一过程需要复杂的匹配规则、名称/地址正常化与标准化。而ETL在处理过程中会定义一个关键数据标准,并在此基础上,制定相应的数据接口标准。

特色功能
  
编辑

ETL过程在很大程度上受企业对源数据的理解程度的影响,也就是说从业务的角度看数据集成非常重要。一个优秀的ETL设计应该具有如下功能: 
  
管理简单

采用元数据方法,集中进行管理；接口、数据格式、传输有严格的规范；尽量不在外部数据源安装软件；数据抽取系统流程自动化,并有自动调度功能；抽取的数据及时、准确、完整；可以提供同各种数据系统的接口,系统适应性强；提供软件框架系统,系统功能改变时,应用程序很少改变便可适应变化；可扩展性强。
  
标准定义数据

合理的业务模型设计对ETL至关重要。数据仓库是企业唯一、真实、可靠的综合数据平台。数据仓库的设计建模一般都依照三范式、星型模型、雪花模型,无论哪种设计思想,都应该最大化地涵盖关键业务数据,把运营环境中杂乱无序的数据结构统一成为合理的、关联的、分析型的新结构,而ETL则会依照模型的定义去提取数据源,进行转换、清洗,并最终加载到目标数据仓库中。
  
模型的重要之处在于对数据做标准化定义,实现统一的编码、统一的分类和组织。标准化定义的内容包括: 标准代码统一、业务术语统一。ETL依照模型进行初始加载、增量加载、缓慢增长维、慢速变化维、事实表加载等数据集成,并根据业务需求制定相应的加载策略、刷新策略、汇总策略、维护策略。
  
拓展新型应用

对业务数据本身及其运行环境的描述与定义的数据,称之为元数据 (metadata) 。元数据是描述数据的数据。从某种意义上说,业务数据主要用于支持业务系统应用的数据,而元数据则是企业信息门户、客户关系管理、数据仓库、决策支持和B2B等新型应用所不可或缺的内容。
  
元数据的典型表现为对象的描述,即对数据库、表、列、列属性 (类型、格式、约束等) 以及主键/外部键关联等等的描述。特别是现行应用的异构性与分布性越来越普遍的情况下,统一的元数据就愈发重要了。"信息孤岛"曾经是很多企业对其应用现状的一种抱怨和概括,而合理的元数据则会有效地描绘出信息的关联性。
  
而元数据对于ETL的集中表现为: 定义数据源的位置及数据源的属性、确定从源数据到目标数据的对应规则、确定相关的业务逻辑、在数据实际加载前的其他必要的准备工作,等等,它一般贯穿整个数据仓库项目,而ETL的所有过程必须最大化地参照元数据,这样才能快速实现ETL。